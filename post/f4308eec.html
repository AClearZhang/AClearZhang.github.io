<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="—关于hadoop.apache.org 官方事务的使用分析： common一般是放置一些公共可供使用和下载的框架等。 Ambari  图形化的hadoop安装版本。商业化做一下cdh  一个商业化、方便操作的hadoop版本。 Spark  广义 hadoop.apache.org 2.2.0  是在2015-2016年比较多人用的。 开发的时候，数据分析  只需要我们进行嵌入的一部分用户的AP">
<meta property="og:type" content="article">
<meta property="og:title" content="day06_BigData渐进学习_aclear_fire">
<meta property="og:url" content="http://blog.aclear.top/post/f4308eec.html">
<meta property="og:site_name" content="少年初心">
<meta property="og:description" content="—关于hadoop.apache.org 官方事务的使用分析： common一般是放置一些公共可供使用和下载的框架等。 Ambari  图形化的hadoop安装版本。商业化做一下cdh  一个商业化、方便操作的hadoop版本。 Spark  广义 hadoop.apache.org 2.2.0  是在2015-2016年比较多人用的。 开发的时候，数据分析  只需要我们进行嵌入的一部分用户的AP">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://pic.aclear.top/02.推荐系统架构-1024x704.png">
<meta property="og:image" content="http://pic.aclear.top/hadoop_编译相关.jpg">
<meta property="og:updated_time" content="2019-10-02T03:40:40.967Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="day06_BigData渐进学习_aclear_fire">
<meta name="twitter:description" content="—关于hadoop.apache.org 官方事务的使用分析： common一般是放置一些公共可供使用和下载的框架等。 Ambari  图形化的hadoop安装版本。商业化做一下cdh  一个商业化、方便操作的hadoop版本。 Spark  广义 hadoop.apache.org 2.2.0  是在2015-2016年比较多人用的。 开发的时候，数据分析  只需要我们进行嵌入的一部分用户的AP">
<meta name="twitter:image" content="http://pic.aclear.top/02.推荐系统架构-1024x704.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.aclear.top/post/f4308eec.html">





  <title>day06_BigData渐进学习_aclear_fire | 少年初心</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">少年初心</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">上进心的男生是有魅力的。不论是学习还是之后工作，有上进心的男生都是发光哒。</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.aclear.top/post/f4308eec.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AClearZhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar_acan.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="少年初心">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">day06_BigData渐进学习_aclear_fire</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-09T15:45:49+08:00">
                2018-01-09
              </time>
            

            

            
          </span>

          
            <span class="post-updated">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i> 
              </span>
              更新于
              <time itemprop="dateUpdated" datetime="2019-10-02T11:40:40+08:00" content="2019-10-02">
                2019-10-02
              </time>
            </span>
          

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-Data/" itemprop="url" rel="index">
                    <span itemprop="name">Big Data</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-superpowers"></i> 阅读次数
              <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6.8k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  26
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>—关于hadoop.apache.org 官方事务的使用分析： common一般是放置一些公共可供使用和下载的框架等。 Ambari  图形化的hadoop安装版本。商业化做一下cdh  一个商业化、方便操作的hadoop版本。 Spark  广义 hadoop.apache.org 2.2.0  是在2015-2016年比较多人用的。 开发的时候，数据分析  只需要我们进行嵌入的一部分用户的API即可。所以官网的API <a href="http://hadoop.apache.org/docs/r2.6.5/api/index.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.6.5/api/index.html</a>  接口是很多doc但建起来的 知道用户接口，把需要的业务逻辑嵌入进去就好。 但是底部的 configuration——表示里面的配置参数，因为数据分析一点API加许多的配置参数进行处理的。但是好在  大部分的值用默认的惨呼就好，用的过程中会说，但是参数配置大全——用的的时候再拿来用即可。 —典型的推荐系统架构，应用的实时计算——看下当时讲的架构图即可 添加一：kafka？   进行实时处理&lt;storm/sparkStreaming&gt;统计当前的最新动态. 添加二：&lt;有些东西只是sql统计不出来，所以要用 深度学习，mahout&lt;根据算法得到的结果，也是得到一些协同过滤算法得到的结果&gt;&gt;sql-&gt;HIVE仓库；  另一个通过mahout-&gt;协同算法得推荐数据。 综上 都要到，推荐原料中，成立为一个表。 [caption id=”attachment_1107” align=”aligncenter” width=”1422”]<img src="http://pic.aclear.top/02.推荐系统架构-1024x704.png" alt="dream"> 推荐系统架构+实时操作[/caption] —Hadoop集群框架搭建 hdfs:name nodename  datanode   datanode datanode … yarn: resourcenode    nodemanager  nodemanage15r  nodemanager ….   —注意hadoop编译，由于hadoop包&lt;原本应该是跨平台的&gt;下载下来之后还需要，利用对应平台的解压缩命令还有maven tar c  java编译库都要和操作系统的存在形式是一样的。 注意：如果只是小小的想要使用  servlet，给hadoop一个内置的netty即可。   PS.:file://      hdfs://   注意哦统一资源定位符，对应的协议。 —关于官网下载的hadoop源码包，因为官网下载下来的都是源码包。 然而hadoop是maven的项目，所以需要在maven上进行下载相应的包、并编译， 利用ant进行打包。<img src="http://pic.aclear.top/hadoop_编译相关.jpg" alt="dream">   </p>
<p>注意：官网上面有：hadoop.src.tar.gz①   hadoop.tar.gz② 其中①是源码包用于进行图片中“hadoop编译.docx”进行tar.gz编译   share/hadoop/hdfs   share下方是jar包   <strong>---</strong>eclipse上面导入jar包需要导入：share/hadoop/hdfs  common、hdfs下面的：jar+lib当中的jar到一个新建的eclipse项目中去。——完成就是hdfs的jar包了。 1.以上hdfs的一些在eclipse上通过hdfs api运行的类似于客户端的操作——称之为HDFS应用开发篇。</p>
<blockquote>
<p><em>hdfs__在生产应用中主要是客户端的开发，其核心步骤是从hdfs__提供的api__中构造一个HDFS__的访问客户端对象，然后通过该客户端对象操作（增删改查）HDFS__上的文件</em></p>
</blockquote>
<p>详情见：7.HDFS的java操作。 <strong>以上</strong>是通过centos当做服务器（所以你会看到，有protobuf当做序列化工具）； windows上eclipse做为客户端调用api学习使用的客户端。（我们当前就是使用的这样一种开发学习方式。）</p>
<p>2.window下开发的说明<br>建议在linux下进行hadoop应用的开发，不会存在兼容性问题。如在window上做客户端应用开发，需要设置以下环境：<br>·在windows的某个目录下解压一个hadoop的安装包<br>·将安装包下的lib和bin目录用对应windows版本平台编译的本地库替换<br>·在window系统中配置HADOOP_HOME指向你解压的安装包<br>·在windows系统的path变量中加入hadoop的bin目录<br>（注意，也就是最近一张图片中windows7编译出来的zip包中bin/lib替换安装包中的bin/lib即可！）</p>
<p>（注意：我们设置HADOOP_HOME+path + windows10编译出来的 bin+lib 替换掉挂网的东西）</p>
<p>/**<br> *<br> * 客户端去操作hdfs时，是有一个用户身份的<br> * 默认情况下，hdfs客户端api会从jvm中获取一个参数来作为自己的用户身份：-DHADOOP_USER_NAME=hadoop<br> *<br> * 也可以在构造客户端fs对象时，通过参数传递进去<br> * @author<br> <em>
 </em>/<br>public class HdfsClientDemo {<br>    FileSystem fs = null;<br>    Configuration conf = null;<br>    @Before<br>    public void init() throws Exception{<br>        conf = new Configuration();<br>        conf.set(“fs.defaultFS”,”hdfs://aclear1:9000”);<br>        //这个是本地的对象<br>        fs = FileSystem.get(conf);<br>//        fs = FileSystem.get(new URI(“hdfs://aclear1:9000”), conf,”hadoop”);<br>        //拿到一个文件系统操作的客户端实例对象<br>        /*fs = FileSystem.get(conf);*/<br>        //可以直接传入 uri和用户身份<br>    }<br>    @Test<br>    public void testUpload() throws Exception {<br>        fs.copyFromLocalFile(new Path(“H:/access.log”), new Path(“/accessFromLocal.log.copy”));<br>        fs.close();<br>//        Thread.sleep(2000);<br>//        fs.copyFromLocalFile(new Path(“G:/access.log”), new Path(“/access.log.copy”));<br>//        fs.close();<br>    }<br>    @Test<br>    public void testDownload() throws Exception {<br>        fs.copyToLocalFile(new Path(“/access.log.copy”), new Path(“d:/“));<br>        fs.close();<br>    }<br><strong>//注意环境问题是主要出在  bin的上面！！！<br>//1.配置好 HADOOP_HOME<br>//2.搞好  bin  lib就好了。（即平台相关性的替换，用在windows上的相关库！相关exe！）<br>//综上所述：解决空格问题一共有两种办法，一个是想办法在环境变量设置的时候用特殊字符给他替换掉，另外一个就<br>//是在写代码的时候 用双引号给有空格的路径给它引起来就OK了<br>    //目录”program files”同时还拥有一个8.3规范的”PROGRA~1”短名称；</strong></p>
<p>  目录 <a href="#_Toc439057207">课程大纲（HADOOP快速入门）…………………………………………………………………………… 2</a></p>
<ol>
<li><a href="#_Toc439057208">HADOOP 快速入门………………………………………………………………………………………….. 3</a></li>
</ol>
<p><a href="#_Toc439057209">什么是HADOOP…………………………………………………………………………………………… 3</a> <a href="#_Toc439057210">HADOOP产生背景……………………………………………………………………………………….. 3</a> <a href="#_Toc439057211">HADOOP在大数据、云计算中的位置和关系……………………………………………………… 3</a> <a href="#_Toc439057212">国内外HADOOP应用案例介绍……………………………………………………………………….. 4</a> <a href="#_Toc439057213">国内HADOOP的就业情况分析……………………………………………………………………….. 5</a> <a href="#_Toc439057214">HADOOP生态圈以及各组成部分的简介……………………………………………………………. 6</a> <a href="#_Toc439057215">分布式系统概述………………………………………………………………………………………….. 6</a></p>
<ol start="2">
<li><a href="#_Toc439057216">HIVE快速入门………………………………………………………………………………………………… 7</a></li>
</ol>
<p><a href="#_Toc439057217">2.1 Hive基本介绍…………………………………………………………………………………………. 7</a> <a href="#_Toc439057218">2.2 Hive的基本使用……………………………………………………………………………………… 8</a> <a href="#_Toc439057219">2.3 数据仓库基本知识………………………………………………………………………………….. 9</a></p>
<ol start="3">
<li><a href="#_Toc439057220">数据分析案列演示………………………………………………………………………………………… 10</a></li>
</ol>
<p><a href="#_Toc439057221">3.1 需求分析…………………………………………………………………………………………….. 10</a> <a href="#_Toc439057222">3.1.1案例名称…………………………………………………………………………………….. 10</a> <a href="#_Toc439057223">3.1.2 案例需求描述……………………………………………………………………………… 10</a> <a href="#_Toc439057224">3.1.3 web点击流日志的数据格式……………………………………………………………. 10</a> <a href="#_Toc439057225">3.1.4 分析指标……………………………………………………………………………………. 11</a> <a href="#_Toc439057226">3.1.5 统计结果数据可视化…………………………………………………………………….. 11</a> <a href="#_Toc439057227">3.2 数据来源分析………………………………………………………………………………………. 12</a> <a href="#_Toc439057228">3.2.1 企业中获取数据的几种方式…………………………………………………………… 12</a> <a href="#_Toc439057229">3.2.2 数据采集……………………………………………………………………………………. 12</a> <a href="#_Toc439057230">3.3 数据处理流程………………………………………………………………………………………. 13</a> <a href="#_Toc439057231">数据预处理/加载入库…………………………………………………………………………… 13</a> <a href="#_Toc439057232">使用Hive做数据ETL…………………………………………………………………………….. 14</a> <a href="#_Toc439057233">使用Hive运算业务指标………………………………………………………………………… 16</a> <a href="#_Toc439057234">将结果数据导出到mysql（sqoop）…………………………………………………………. 17</a> <a href="#_Toc439057235">结果展现——数据可视化………………………………………………………………………. 17</a></p>
<ol start="4">
<li><a href="#_Toc439057236">集群搭建…………………………………………………………………………………………………….. 18</a></li>
</ol>
<p><a href="#_Toc439057237">4.1 HADOOP集群搭建…………………………………………………………………………………. 18</a> <a href="#_Toc439057238">4.1.1集群简介：………………………………………………………………………………….. 18</a> <a href="#_Toc439057239">4.1.2服务器准备………………………………………………………………………………….. 18</a> <a href="#_Toc439057240">4.1.3网络环境准备………………………………………………………………………………. 18</a> <a href="#_Toc439057241">4.1.4服务器系统设置……………………………………………………………………………. 18</a> <a href="#_Toc439057242">4.1.5 Jdk环境安装………………………………………………………………………………… 19</a> <a href="#_Toc439057243">4.1.6 HADOOP安装部署…………………………………………………………………………. 19</a> <a href="#_Toc439057244">4.1.7 启动集群……………………………………………………………………………………. 21</a> <a href="#_Toc439057245">4.1.8 测试………………………………………………………………………………………….. 21</a> <a href="#_Toc439057246">4.2 Hive搭建……………………………………………………………………………………………… 22</a> <a href="#_Toc439057247">Hive的配置安装………………………………………………………………………………….. 22</a> <a href="#_Toc439057248">Hive的使用………………………………………………………………………………………… 23</a> <a href="#_Toc439057249">Hive运行测试……………………………………………………………………………………… 23</a>    </p>
<h1 id="课程大纲（HADOOP快速入门）"><a href="#课程大纲（HADOOP快速入门）" class="headerlink" title="课程大纲（HADOOP快速入门）"></a>课程大纲（HADOOP快速入门）</h1><p>HADOOP快速入门</p>
<p>HADOOP快速入门</p>
<p>HADOOP产生背景</p>
<p>HADOOP在大数据、云计算中的位置和关系</p>
<p>国内外HADOOP应用案例介绍</p>
<p>国内HADOOP的就业情况分析及课程大纲介绍</p>
<p>分布式系统概述</p>
<p>HADOOP生态圈以及各组成部分的简介</p>
<p>Hive快速入门</p>
<p>Hive快速入门</p>
<p>Hive基本介绍</p>
<p>Hive的使用</p>
<p>数据仓库基本知识</p>
<p>数据分析案例演示</p>
<p>需求分析</p>
<p>案列：定义需求、介绍数据格式</p>
<p>数据获取</p>
<p>企业中获取数据的几种方式</p>
<p>将文件直接导入到数据仓库</p>
<p>将数据库的数据导入到数据仓库（sqoop）</p>
<p>数据处理</p>
<p>使用Hive对数进行清洗（ETL的过程）</p>
<p>数据计算</p>
<p>使用Hive对数据进行计算</p>
<p>数据展现</p>
<p>将结果数据导出到mysql（sqoop）</p>
<pre><code>学习目标： 第一天接触具体的大数据框架，总目标是让学习者建立起大数据和分布式的宏观概念 1、理解hadoop是什么，用于做什么，大体上怎么用 2、理解hive是什么，用于做什么，大体上怎么用 3、通过一个案例的演示说明，理解数据挖掘系统的基本流程和结构    
</code></pre><h1 id="1-HADOOP背景介绍"><a href="#1-HADOOP背景介绍" class="headerlink" title="1. HADOOP背景介绍"></a>1. HADOOP背景介绍</h1><h2 id="1-1-什么是HADOOP"><a href="#1-1-什么是HADOOP" class="headerlink" title="1.1 什么是HADOOP"></a>1.1 什么是HADOOP</h2><ol>
<li>HADOOP是apache旗下的一套开源<strong>软件平台</strong></li>
<li>HADOOP提供的功能：利用服务器集群，根据用户的自定义业务逻辑，<strong>对海量数据进行分布式处理</strong></li>
<li>HADOOP的核心组件有<ol>
<li>HDFS（分布式文件系统）</li>
<li>YARN（运算资源调度系统）</li>
<li>MAPREDUCE（分布式运算编程框架）</li>
</ol>
</li>
<li>广义上来说，HADOOP通常是指一个更广泛的概念——HADOOP生态圈</li>
</ol>
<h2 id="1-2-HADOOP产生背景"><a href="#1-2-HADOOP产生背景" class="headerlink" title="1.2 HADOOP产生背景"></a>1.2 HADOOP产生背景</h2><ol>
<li>HADOOP<strong>最早起源于Nutch</strong>。Nutch的设计目标是构建一个大型的全网搜索引擎，包括网页抓取、索引、查询等功能，但随着抓取网页数量的增加，<strong>遇到了严重的可扩展性问题——</strong>如何解决数十亿网页的存储和索引问题。</li>
<li>2003年、2004年<strong>谷歌发表的两篇论文为该问题提供了可行的解决方案</strong>。</li>
</ol>
<p>——分布式文件系统（GFS），可用于处理海量网页的<strong>存储</strong> ——分布式计算框架MAPREDUCE，可用于处理海量网页的<strong>索引计算</strong>问题。</p>
<ol start="3">
<li>Nutch的开发人员完成了相应的<strong>开源实现**</strong>HDFS<strong>**和MAPREDUCE</strong>，并从Nutch中剥离成为独立项目HADOOP，到2008年1月，HADOOP成为Apache顶级项目，迎来了它的快速发展期。</li>
</ol>
<h2 id="1-3-HADOOP在大数据、云计算中的位置和关系"><a href="#1-3-HADOOP在大数据、云计算中的位置和关系" class="headerlink" title="1.3 HADOOP在大数据、云计算中的位置和关系"></a>1.3 HADOOP在大数据、云计算中的位置和关系</h2><ol>
<li>云计算是分布式计算、并行计算、网格计算、多核计算、网络存储、虚拟化、负载均衡等传统计算机技术和互联网技术融合发展的产物。借助IaaS(基础设施即服务)、PaaS(平台即服务)、SaaS（软件即服务）等业务模式，把强大的计算能力提供给终端用户。</li>
</ol>
<ol start="2">
<li>现阶段，云计算的<strong>两大底层支撑技术</strong>为“<strong>虚拟化</strong>”和“<strong>大数据技术</strong>”</li>
</ol>
<ol start="3">
<li>而HADOOP则是云计算的PaaS层的解决方案之一，并不等同于PaaS，更不等同于云计算本身。</li>
</ol>
<h2 id="1-4-国内外HADOOP应用案例介绍"><a href="#1-4-国内外HADOOP应用案例介绍" class="headerlink" title="1.4 国内外HADOOP应用案例介绍"></a>1.4 国内外HADOOP应用案例介绍</h2><p><strong>1**</strong>、HADOOP<strong>**应用于数据服务基础平台建设</strong>   <strong>2/HADOOP**</strong>用于用户画像<strong>   </strong>3<strong><strong>、HADOOP</strong></strong>用于网站点击流日志数据挖掘**</p>
<h2 id="1-5-国内HADOOP的就业情况分析"><a href="#1-5-国内HADOOP的就业情况分析" class="headerlink" title="1.5 国内HADOOP的就业情况分析"></a>1.5 国内HADOOP的就业情况分析</h2><ul>
<li>HADOOP就业整体情况</li>
</ul>
<ol>
<li>大数据产业已纳入<strong>国家十三五规划</strong></li>
<li>各大城市都在进行<strong>智慧城市项目</strong>建设，而智慧城市的根基就是大数据综合平台</li>
<li>互联网时代数据的种类，增长都呈现<strong>爆发式增长</strong>，各行业对数据的价值日益重视</li>
<li>相对于传统JAVAEE技术领域来说，大数据领域的<strong>人才相对稀缺</strong></li>
<li>随着现代社会的发展，数据处理和数据挖掘的重要性只会增不会减，因此，大数据技术是一个尚在蓬勃发展且具有<strong>长远前景的领域</strong></li>
</ol>
<ul>
<li>HADOOP就业职位要求</li>
</ul>
<p>大数据是个复合专业，包括应用开发、软件平台、算法、数据挖掘等，因此，<strong>大数据技术领域的就业选择是多样的</strong>，但就HADOOP而言，通常都需要具备以下技能或知识：</p>
<ol>
<li>HADOOP分布式集群的平台搭建</li>
<li>HADOOP分布式文件系统HDFS的原理理解及使用</li>
<li>HADOOP分布式运算框架MAPREDUCE的原理理解及编程</li>
<li>Hive数据仓库工具的熟练应用</li>
<li>Flume、sqoop、oozie等辅助工具的熟练使用</li>
<li>Shell/python等脚本语言的开发能力</li>
</ol>
<ul>
<li>HADOOP相关职位的薪资水平</li>
</ul>
<p>大数据技术或具体到HADOOP的就业需求目前主要集中在北上广深一线城市，<strong>薪资待遇普遍高于传统**</strong>JAVAEE<strong>**开发人员</strong>，以北京为例：      </p>
<h2 id="1-6-HADOOP生态圈以及各组成部分的简介"><a href="#1-6-HADOOP生态圈以及各组成部分的简介" class="headerlink" title="1.6 HADOOP生态圈以及各组成部分的简介"></a>1.6 HADOOP生态圈以及各组成部分的简介</h2><p>各组件简介   重点组件： HDFS：分布式文件系统 MAPREDUCE：分布式运算程序开发框架 HIVE：基于大数据技术（文件系统+运算框架）的SQL数据仓库工具 HBASE：基于HADOOP的分布式海量数据库 <strong>ZOOKEEPER**</strong>：分布式协调服务基础组件** Mahout：基于mapreduce/spark/flink等分布式运算框架的机器学习算法库 Oozie：工作流调度框架 Sqoop：数据导入导出工具 Flume：日志数据采集框架      </p>
<h1 id="2-分布式系统概述"><a href="#2-分布式系统概述" class="headerlink" title="2 分布式系统概述"></a>2 分布式系统概述</h1><p><em>注：由于大数据技术领域的各类技术框架基本上都是分布式系统，因此，理解hadoop__、storm__、spark__等技术框架，都需要具备基本的分布式系统概念</em>  </p>
<h2 id="2-1-分布式软件系统-Distributed-Software-Systems"><a href="#2-1-分布式软件系统-Distributed-Software-Systems" class="headerlink" title="2.1 分布式软件系统(Distributed Software Systems)"></a>2.1 分布式软件系统(Distributed Software Systems)</h2><ul>
<li>该软件系统会划分成多个子系统或模块，各自运行在不同的机器上，子系统或模块之间通过网络通信进行协作，实现最终的整体功能</li>
<li>比如分布式操作系统、分布式程序设计语言及其编译(解释)系统、分布式文件系统和分布式数据库系统等。</li>
</ul>
<h2 id="2-2-分布式软件系统举例：solrcloud"><a href="#2-2-分布式软件系统举例：solrcloud" class="headerlink" title="2.2 分布式软件系统举例：solrcloud"></a>2.2 分布式软件系统举例：solrcloud</h2><ol>
<li>一个solrcloud集群通常有多台solr服务器</li>
<li>每一个solr服务器节点负责存储整个索引库的若干个shard（数据分片）</li>
<li>每一个shard又有多台服务器存放若干个副本互为主备用</li>
<li>索引的建立和查询会在整个集群的各个节点上并发执行</li>
<li>solrcloud集群作为整体对外服务，而其内部细节可对客户端透明</li>
</ol>
<p><strong>总结：利用多个节点共同协作完成一项或多项具体业务功能的系统就是分布式系统。</strong>  </p>
<h2 id="2-3-分布式应用系统模拟开发"><a href="#2-3-分布式应用系统模拟开发" class="headerlink" title="2.3 分布式应用系统模拟开发"></a>2.3 分布式应用系统模拟开发</h2><p><strong>需求：</strong>可以实现由主节点将运算任务发往从节点，并将各从节点上的任务启动； <strong>程序清单：</strong> AppMaster AppSlave/APPSlaveThread Task <strong>程序运行逻辑流程：</strong>  </p>
<h1 id="3-离线数据分析流程介绍"><a href="#3-离线数据分析流程介绍" class="headerlink" title="3. 离线数据分析流程介绍"></a>3. 离线数据分析流程介绍</h1><p><em>注：本环节主要感受数据分析系统的宏观概念及处理流程，初步理解hadoop__等框架在其中的应用环节，不用过于关注代码细节</em>  一个应用广泛的数据分析系统：“web日志数据挖掘”</p>
<h2 id="3-1-需求分析"><a href="#3-1-需求分析" class="headerlink" title="3.1 需求分析"></a>3.1 需求分析</h2><h3 id="3-1-1-案例名称"><a href="#3-1-1-案例名称" class="headerlink" title="3.1.1 案例名称"></a>3.1.1 案例名称</h3><p>“网站或。  </p>
<h3 id="3-1-2-案例需求描述"><a href="#3-1-2-案例需求描述" class="headerlink" title="3.1.2 案例需求描述"></a>3.1.2 案例需求描述</h3><p>“Web点击流日志”包含着网站运营很重要的信息，通过日志分析，我们可以知道网站的访问量，哪个网页访问人数最多，哪个网页最有价值，广告转化率、访客的来源信息，访客的终端信息等。  </p>
<h3 id="3-1-3-数据来源"><a href="#3-1-3-数据来源" class="headerlink" title="3.1.3 数据来源"></a>3.1.3 数据来源</h3><p>本案例的数据主要由<strong>用户的点击行为记录</strong> 获取方式：在页面预埋一段js程序，为页面上想要监听的标签绑定事件，只要用户点击或移动到标签，即可触发ajax请求到后台servlet程序，用log4j记录下事件信息，从而在web服务器（nginx、tomcat等）上形成不断增长的日志文件。 形如：</p>
<p>58.215.204.118 - - [18/Sep/2013:06:51:35 +0000] “GET /wp-includes/js/jquery/jquery.js?ver=1.10.2 HTTP/1.1” 304 0 “<a href="http://blog.fens.me/nodejs-socketio-chat/&quot;" target="_blank" rel="noopener">http://blog.fens.me/nodejs-socketio-chat/&quot;</a> “Mozilla/5.0 (Windows NT 5.1; rv:23.0) Gecko/20100101 Firefox/23.0”</p>
<h2 id="3-2-数据处理流程"><a href="#3-2-数据处理流程" class="headerlink" title="3.2 数据处理流程"></a>3.2 数据处理流程</h2><h3 id="3-2-1-流程图解析"><a href="#3-2-1-流程图解析" class="headerlink" title="3.2.1 流程图解析"></a>3.2.1 流程图解析</h3><p>本案例跟典型的BI系统极其类似，整体流程如下： 但是，由于本案例的前提是处理海量数据，因而，流程中各环节所使用的技术则跟传统BI完全不同，后续课程都会一一讲解：</p>
<ul>
<li>数据采集：定制开发采集程序，或使用开源框架FLUME</li>
<li>数据预处理：定制开发mapreduce程序运行于hadoop集群</li>
<li>数据仓库技术：基于hadoop之上的Hive</li>
<li>数据导出：基于hadoop的sqoop数据导入导出工具</li>
<li>数据可视化：定制开发web程序或使用kettle等产品</li>
<li>整个过程的流程调度：hadoop生态圈中的oozie工具或其他类似开源产品</li>
</ul>
<h3 id="3-2-2-项目技术架构图"><a href="#3-2-2-项目技术架构图" class="headerlink" title="3.2.2 项目技术架构图"></a>3.2.2 项目技术架构图</h3><h3 id="3-2-3-项目相关截图（感性认识，欣赏即可）"><a href="#3-2-3-项目相关截图（感性认识，欣赏即可）" class="headerlink" title="3.2.3 项目相关截图（感性认识，欣赏即可）"></a>3.2.3 项目相关截图（感性认识，欣赏即可）</h3><ol>
<li>Mapreudce程序运行</li>
</ol>
<ol>
<li>在Hive中查询数据</li>
</ol>
<ol>
<li>将统计结果导入mysql</li>
</ol>
<p>./sqoop export –connect jdbc:mysql://localhost:3306/weblogdb –username root –password root  –table t_display_xx  –export-dir /user/hive/warehouse/uv/dt=2014-08-03</p>
<h2 id="3-3-项目最终效果"><a href="#3-3-项目最终效果" class="headerlink" title="3.3 项目最终效果"></a>3.3 项目最终效果</h2><p>经过完整的数据处理流程后，会周期性输出各类统计指标的报表，在生产实践中，最终需要将这些报表数据以可视化的形式展现出来，本案例采用web程序来实现数据可视化 效果如下所示：          </p>
<h1 id="4-集群搭建"><a href="#4-集群搭建" class="headerlink" title="4. 集群搭建"></a>4. 集群搭建</h1><h2 id="4-1-HADOOP集群搭建"><a href="#4-1-HADOOP集群搭建" class="headerlink" title="4.1 HADOOP集群搭建"></a>4.1 HADOOP集群搭建</h2><h3 id="4-1-1集群简介"><a href="#4-1-1集群简介" class="headerlink" title="4.1.1集群简介"></a>4.1.1集群简介</h3><p>HADOOP集群具体来说包含两个集群：HDFS集群和YARN集群，两者逻辑上分离，但物理上常在一起 HDFS集群： 负责海量数据的存储，集群中的角色主要有 NameNode / DataNode YARN集群： 负责海量数据运算时的资源调度，集群中的角色主要有 ResourceManager /NodeManager <em>(<strong>那mapreduce</strong>是什么呢？它其实是一个应用程序开发包)</em>  本集群搭建案例，以5节点为例进行搭建，角色分配如下：</p>
<p>hdp-node-01    NameNode  SecondaryNameNode hdp-node-02    ResourceManager hdp-node-03              DataNode    NodeManager hdp-node-04              DataNode    NodeManager hdp-node-05              DataNode    NodeManager</p>
<p>部署图如下：</p>
<h3 id="4-1-2服务器准备"><a href="#4-1-2服务器准备" class="headerlink" title="4.1.2服务器准备"></a>4.1.2服务器准备</h3><p>本案例使用虚拟机服务器来搭建HADOOP集群，所用软件及版本：</p>
<ul>
<li>Vmware 11.0</li>
<li>Centos 5  64bit</li>
</ul>
<h3 id="4-1-3网络环境准备"><a href="#4-1-3网络环境准备" class="headerlink" title="4.1.3网络环境准备"></a>4.1.3网络环境准备</h3><ul>
<li>采用NAT方式联网</li>
<li>网关地址：168.33.1</li>
<li>3个服务器节点IP地址：168.33.101、192.168.33.102、192.168.33.103</li>
<li>子网掩码：255.255.0</li>
</ul>
<h3 id="4-1-4服务器系统设置"><a href="#4-1-4服务器系统设置" class="headerlink" title="4.1.4服务器系统设置"></a>4.1.4服务器系统设置</h3><ul>
<li>添加HADOOP用户</li>
<li>为HADOOP用户分配sudoer权限</li>
<li>同步时间</li>
<li>设置主机名<ul>
<li>hdp-node-01</li>
<li>hdp-node-02</li>
<li>hdp-node-03</li>
</ul>
</li>
<li>配置内网域名映射：<ul>
<li>168.33.101 hdp-node-01</li>
<li>168.33.102 hdp-node-02</li>
<li>168.33.103 hdp-node-03</li>
</ul>
</li>
<li>配置ssh免密登陆</li>
<li>配置防火墙</li>
</ul>
<h3 id="4-1-5-Jdk环境安装"><a href="#4-1-5-Jdk环境安装" class="headerlink" title="4.1.5 Jdk环境安装"></a>4.1.5 Jdk环境安装</h3><ul>
<li>上传jdk安装包</li>
<li>规划安装目录 /home/hadoop/apps/jdk_1.7.65</li>
<li>解压安装包</li>
<li>配置环境变量 /etc/profile</li>
</ul>
<h3 id="4-1-6-HADOOP安装部署"><a href="#4-1-6-HADOOP安装部署" class="headerlink" title="4.1.6 HADOOP安装部署"></a>4.1.6 HADOOP安装部署</h3><ul>
<li>上传HADOOP安装包</li>
<li>规划安装目录 /home/hadoop/apps/hadoop-2.6.1</li>
<li>解压安装包</li>
<li>修改配置文件 $HADOOP_HOME/etc/hadoop/</li>
</ul>
<p>1最简化配置如下： vi  hadoop-env.sh</p>
<p># The java implementation to use. export JAVA_HOME=/home/hadoop/apps/jdk1.7.0_51</p>
<p>  vi  core-site.xml</p>
<configuration> <!--nameNode服务器上的节点 --> <property> <name>fs.defaultFS</name> <value>hdfs://aclear1:9000</value> </property> <!--集群中的每一台的工作目录 --> <property> <name>hadoop.tmp.dir</name> <value>/home/Hadoop/hdpdata</value> </property> </configuration>

<p>vi  hdfs-site.xml</p>
<p><!--这里面可以不用配置，因为有些事默认已经配置了--\>   <configuration> <property> <name>dfs.namenode.name.dir</name> <value>/home/hadoop/data/name</value> </property> <property> <name>dfs.datanode.data.dir</name> <value>/home/hadoop/data/data</value> </property>     <!--注意只配置了一个这个：每个文件有两个副本 --> <property> <name>dfs.replication</name> <value>2</value> </property>   <property> <name>dfs.secondary.http.address</name> <value>hdp-node-01:50090</value> </property> </p>
<pre><code>vi  mapred-site.xml
</code></pre><configuration> <property> <!--mapreduce 对应的运行框架以及对应 框架的yarn运行环境，local（默认这样就是单机版本了）--> <name>mapreduce.framework.name</name> <value>yarn</value> </property> </configuration>

<p>  vi  yarn-site.xml</p>
<p><configuration> <!--寻找yarn的老大resourcemanager，对应在那一台集群上。 --> <property> <name>yarn.resourcemanager.hostname</name> <value>aclear1</value> </property>   <!--注意 对应yarn需要的服务，数值是什么--> <property> <name>yarn.nodemanager.aux-services</name> <value>mapreduce_shuffle</value> </property> </configuration> 对应放置在 2 3 4上</p>
<p>所以我们 由以上的配置得出一个问题&lt;在此之前先配置下面的东西&gt;： Namenode 以及 resourcemanager 都已经出现了。对应的集群子服务器并没有出现：所以 其实aclear1 我们已经写死。其它的子服务器会按照目前启动的服务器自行装载：   Aclear1通过： Hadoop-daemon.sh start namenode  //启动namenode服务器 //注意 jetty是在 50070&lt;端口有个网页可以看到对应服务器配合的 情况有多少可用东西。&gt;   JPS Aclear2通过： Hadoop-daemon.sh start datanode //启动当做datanode   //原理： 因为hadoop的配置文件已经配置的完全一致了，所以可以相互握手</p>
<p>—2HDFS进行格式化— &lt;因为这个是建立在 Linux物理目录之上的，也就是说 HDFS是格式化建立一个逻辑文件层，分块 进行大型数据、文件集的处理&gt; Source /etc/profile   人机交互&lt;脚本执行进行实现&gt;   必须注意：学会使用.log日志 查找、发现错误：</p>
<p>问题：下面   vi  /etc/Hadoop/salves  //纯粹是给自动化启动脚本用的！——apps/Hadoop/../start-all.sh 注意这个是 aclear2 都必须是主机名称！</p>
<p>Aclear2 Aclear3 Aclear4</p>
<p>  Start-dfs.sh   //只在一个namenode  服务器去做即可   //别忘了配置hadoop用户的免密登录—— ssh-keygen -t rsa Ssh-copy-id aclear2 …   P.S.：start-all.sh  ==   start-dfs.sh  &amp;&amp;  start-yarn.sh //配置 secondary namenode //在hdfs–</p>
<p>注意： 深入理解，查看对应的  启动方式得知： Ssh aclear1 Hadoop-daemon.sh start namenode   对比：yarn-daemon.sh  start resourcemanager  这样启动  </p>
<pre><code>//动态上线  动态下限：一台机器 三个副本：上方副本是：2  所以每个数据都是有2个副本！ //我们安装集群最常见问题：  权限不统一问题！——所以最好用sudo来进行权限的获取！！！   //配置文件少 或 写错文字  //日志文件会看到！ 对了 //ssh 免密登录没配好，然后连接超时 —— 没启动起来！ Unknown host——统统用主机名！不用IP！  
</code></pre><h3 id="4-1-7-启动集群"><a href="#4-1-7-启动集群" class="headerlink" title="4.1.7 启动集群"></a>4.1.7 启动集群</h3><p>初始化HDFS 生成namenode初始目录，对应的账本、自己需要的框架结构</p>
<p>hadoop  namenode  -format</p>
<p>  启动HDFS</p>
<p>sbin/start-dfs.sh</p>
<p>  启动YARN</p>
<p>sbin/start-yarn.sh</p>
<p>测试：<a href="http://192.168.78.201:50090/status.html" target="_blank" rel="noopener">http://192.168.78.201:50090/status.html</a>   这个放置在 hdfs-site里面可以自定义端口！</p>
<h3 id="4-1-8-测试"><a href="#4-1-8-测试" class="headerlink" title="4.1.8 测试"></a>4.1.8 测试</h3><h4 id="1、上传文件到HDFS"><a href="#1、上传文件到HDFS" class="headerlink" title="1、上传文件到HDFS"></a>1、上传文件到HDFS</h4><p>从本地上传一个文本文件到hdfs的/wordcount/input目录下</p>
<p>[HADOOP@hdp-node-01 ~]$ HADOOP fs -mkdir -p /wordcount/input       //父类也可以创建出来 [HADOOP@hdp-node-01 ~]$ HADOOP fs -put /home/HADOOP/somewords.txt  /wordcount/input</p>
<h4 id="2、运行一个mapreduce程序"><a href="#2、运行一个mapreduce程序" class="headerlink" title="2、运行一个mapreduce程序"></a>2、运行一个mapreduce程序</h4><p>在HADOOP安装目录下，运行一个示例mr程序</p>
<p>cd $HADOOP_HOME/share/hadoop/mapreduce/ hadoop jar mapredcue-example-2.6.1.jar wordcount /wordcount/input  /wordcount/output   //注意 第一个：hadoop jar 启动share文件夹当中，mapreduce的jar包的wordcount函数：两个参数：第一个是需要同级的文件夹在哪  第二个：需要输出结果到那里去并且不能存在</p>
<h1 id="5-集群使用初步"><a href="#5-集群使用初步" class="headerlink" title="5 集群使用初步"></a>5 集群使用初步</h1><h2 id="5-1-HDFS使用"><a href="#5-1-HDFS使用" class="headerlink" title="5.1 HDFS使用"></a>5.1 HDFS使用</h2><p>1、查看集群状态 命令：   hdfs  dfs admin  –report 可以看出，集群共有3个datanode可用 也可打开web控制台查看HDFS集群信息，在浏览器打开<a href="http://hdp-node-01:50070/" target="_blank" rel="noopener">http://hdp-node-01:50070/</a> 2、上传文件到HDFS</p>
<ul>
<li>查看HDFS中的目录信息</li>
</ul>
<p>命令：   hadoop  fs  –ls  /  </p>
<ul>
<li>上传文件</li>
</ul>
<p>命令：   hadoop  fs  -put  ./ scala-2.10.6.tgz  to  /  </p>
<ul>
<li>从HDFS下载文件</li>
</ul>
<p>命令：  hadoop  fs  -get  /yarn-site.xml             //注意！：1.在环境变量中配置HADOOP_HOME     2.bin .和lib 替换为已经在win10用c编译好的bin  和  lib</p>
<h2 id="5-2-MAPREDUCE使用"><a href="#5-2-MAPREDUCE使用" class="headerlink" title="5.2 MAPREDUCE使用"></a>5.2 MAPREDUCE使用</h2><p>mapreduce是hadoop中的分布式运算编程框架，只要按照其编程规范，只需要编写少量的业务逻辑代码即可实现一个强大的海量数据并发处理程序</p>
<h3 id="5-2-1-Demo开发——wordcount"><a href="#5-2-1-Demo开发——wordcount" class="headerlink" title="5.2.1 Demo开发——wordcount"></a>5.2.1 Demo开发——wordcount</h3><p>1、需求 从大量（比如T级别）文本文件中，统计出每一个单词出现的总次数   2、mapreduce实现思路 Map阶段：</p>
<ol>
<li>从HDFS的源数据文件中逐行读取数据</li>
<li>将每一行数据切分出单词</li>
<li>为每一个单词构造一个键值对(单词，1)</li>
<li><p>将键值对发送给reduce</p>
<p>Reduce阶段：</p>
</li>
<li><p>接收map阶段输出的单词键值对</p>
</li>
<li>将相同单词的键值对汇聚成一组</li>
<li>对每一组，遍历组中的所有“值”，累加求和，即得到每一个单词的总次数</li>
<li>将(单词，总次数)输出到HDFS的文件中</li>
</ol>
<ul>
<li>具体编码实现</li>
</ul>
<p>(1)定义一个mapper类</p>
<p>//首先要定义四个泛型的类型 //keyin:  LongWritable    valuein: Text //keyout: Text            valueout:IntWritable   public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt;{ //map方法的生命周期：  框架每传一行数据就被调用一次 //key :  这一行的起始点在文件中的偏移量 //value: 这一行的内容 @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException { //拿到一行数据转换为string String line = value.toString(); //将这一行切分出各个单词 String[] words = line.split(“ “); //遍历数组，输出&lt;单词，1&gt; for(String word:words){ context.write(new Text(word), new IntWritable(1)); } } }</p>
<p>  (2)定义一个reducer类</p>
<pre><code>//生命周期：框架每传递进来一个kv 组，reduce方法被调用一次 @Override protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException { //定义一个计数器 int count = 0; //遍历这一组kv的所有v，累加到count中 for(IntWritable value:values){ count += value.get(); } context.write(key, new IntWritable(count)); } }
</code></pre><p>  (3)定义一个主类，用来描述job并提交job</p>
<p>public class WordCountRunner { //把业务逻辑相关的信息（哪个是mapper，哪个是reducer，要处理的数据在哪里，输出的结果放哪里。。。。。。）描述成一个job对象 //把这个描述好的job提交给集群去运行 public static void main(String[] args) throws Exception { Configuration conf = new Configuration(); Job wcjob = Job.getInstance(conf); //指定我这个job所在的jar包 //               wcjob.setJar(“/home/hadoop/wordcount.jar”); wcjob.setJarByClass(WordCountRunner.class);   wcjob.setMapperClass(WordCountMapper.class); wcjob.setReducerClass(WordCountReducer.class); //设置我们的业务逻辑Mapper类的输出key和value的数据类型 wcjob.setMapOutputKeyClass(Text.class); wcjob.setMapOutputValueClass(IntWritable.class); //设置我们的业务逻辑Reducer类的输出key和value的数据类型 wcjob.setOutputKeyClass(Text.class); wcjob.setOutputValueClass(IntWritable.class);   //指定要处理的数据所在的位置 FileInputFormat.setInputPaths(wcjob, “hdfs://hdp-server01:9000/wordcount/data/big.txt”); //指定处理完成之后的结果所保存的位置 FileOutputFormat.setOutputPath(wcjob, new Path(“hdfs://hdp-server01:9000/wordcount/output/“));   //向yarn集群提交这个job boolean res = wcjob.waitForCompletion(true); System.exit(res?0:1); }</p>
<h3 id="5-2-2-程序打包运行"><a href="#5-2-2-程序打包运行" class="headerlink" title="5.2.2 程序打包运行"></a>5.2.2 程序打包运行</h3><ol>
<li>将程序打包</li>
<li>准备输入数据</li>
</ol>
<p>vi  /home/hadoop/test.txt</p>
<p>Hello tom Hello jim Hello ketty Hello world Ketty tom</p>
<p>在hdfs上创建输入数据文件夹： hadoop   fs  mkdir  -p  /wordcount/input 将words.txt上传到hdfs上 hadoop  fs  –put  /home/hadoop/words.txt  /wordcount/input  </p>
<ol start="3">
<li>将程序jar包上传到集群的任意一台服务器上</li>
</ol>
<ol start="4">
<li>使用命令启动执行wordcount程序jar包</li>
</ol>
<p>$ hadoop jar wordcount.jar cn.itcast.bigdata.mrsimple.WordCountDriver /wordcount/input /wordcount/out</p>
<ol start="5">
<li>查看执行结果</li>
</ol>
<p>$ hadoop fs –cat /wordcount/out/part-r-00000 HADOOP（hdfs、MAPREDUCE、yarn）  元老级大数据处理技术框架，擅长离线数据分析 Zookeeper   分布式协调服务基础组件 Hbase  分布式海量数据库，离线分析和在线业务通吃 Hive sql 数据仓库工具，使用方便，功能丰富，基于MR延迟大 Sqoop数据导入导出工具 Flume数据采集框架 一般中型的网站(10W的PV以上)，每天会产生1G以上Web日志文件。大型或超大型的网站，可能每小时就会产生10G的数据量。 具体来说，比如某电子商务网站，在线团购业务。每日PV数100w，独立IP数5w。用户通常在工作日上午10:00-12:00和下午15:00-18:00访问量最大。日间主要是通过PC端浏览器访问，休息日及夜间通过移动设备访问较多。网站搜索浏量占整个网站的80%，PC用户不足1%的用户会消费，移动用户有5%会消费。   对于日志的这种规模的数据，用HADOOP进行日志分析，是最适合不过的了。</p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>(っ•̀ω•́)っ✎⁾⁾ 坚持技术学习、内容输出与分享，您的支持将鼓励我继续创作！(*/ω＼*)<br>( • ̀ω•́ )✧如有疑问或需要技术讨论，请留言或发邮件到 aclearzhang@qq.com.(*･ω< ) </div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="http://pic.aclear.top/pay-wechat1.png" alt="AClearZhang 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="http://pic.aclear.top/pay-ali1.png" alt="AClearZhang 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：：</strong>
    AClearZhang
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：：</strong>
    <a href="1103.html" title="day06_BigData渐进学习_aclear_fire">1103.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      

      
      
        <div class="post-widgets">
        
          <div class="wp_rating">
            <div id="wpac-rating"></div>
          </div>
        

        

        
          
          <div id="needsharebutton-postbottom">
            <span class="btn">
              <i class="fa fa-share-alt" aria-hidden="true"></i>
            </span>
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/post/af273ff9.html" rel="next" title="day05_BigData渐进学习_aclear_fire">
                <i class="fa fa-chevron-left"></i> day05_BigData渐进学习_aclear_fire
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/post/a9a3267.html" rel="prev" title="强大的vim快捷键大全">
                强大的vim快捷键大全 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80NTc5Ni8yMjMwNw=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar_acan.jpg" alt="AClearZhang">
            
              <p class="site-author-name" itemprop="name">AClearZhang</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">206</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">113</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/AClearZhang" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:aclearzhang@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://spencerwoo.com/" title="SpenWoo" target="_blank" rel="nofollow">SpenWoo</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.dajipai.cc/" title="鸡排酱" target="_blank" rel="nofollow">鸡排酱</a>
                  </li>
                
              </ul>
            </div>
          

          <!-- none-select-br -->

<p></p>

<!-- hitokoto -->

<div class="hitokoto-title">
	<i class="fa fa-paragraph"></i>
	<b>一言</b>
</div>

<div id="hitokoto">:D 获取中...</div>
<i id="hitofrom">:D 获取中...</i>

<script src="https://cdn.jsdelivr.net/npm/bluebird@3/js/browser/bluebird.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/whatwg-fetch@2.0.3/fetch.min.js"></script>
<script>
  fetch('https://v1.hitokoto.cn')
    .then(function (res){
      return res.json();
    })
    .then(function (data) {
      var hitokoto = document.getElementById('hitokoto');
      hitokoto.innerText = '\xa0\xa0\xa0\xa0\xa0\xa0\xa0' + data.hitokoto;
      var hitofrom = document.getElementById('hitofrom');
      hitofrom.innerText = "——" + data.from + '\xa0'; 
    })
    .catch(function (err) {
      console.error(err);
    })
</script>

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#课程大纲（HADOOP快速入门）"><span class="nav-number">1.</span> <span class="nav-text">课程大纲（HADOOP快速入门）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-HADOOP背景介绍"><span class="nav-number">2.</span> <span class="nav-text">1. HADOOP背景介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-什么是HADOOP"><span class="nav-number">2.1.</span> <span class="nav-text">1.1 什么是HADOOP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-HADOOP产生背景"><span class="nav-number">2.2.</span> <span class="nav-text">1.2 HADOOP产生背景</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-HADOOP在大数据、云计算中的位置和关系"><span class="nav-number">2.3.</span> <span class="nav-text">1.3 HADOOP在大数据、云计算中的位置和关系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-国内外HADOOP应用案例介绍"><span class="nav-number">2.4.</span> <span class="nav-text">1.4 国内外HADOOP应用案例介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-5-国内HADOOP的就业情况分析"><span class="nav-number">2.5.</span> <span class="nav-text">1.5 国内HADOOP的就业情况分析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-6-HADOOP生态圈以及各组成部分的简介"><span class="nav-number">2.6.</span> <span class="nav-text">1.6 HADOOP生态圈以及各组成部分的简介</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-分布式系统概述"><span class="nav-number">3.</span> <span class="nav-text">2 分布式系统概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-分布式软件系统-Distributed-Software-Systems"><span class="nav-number">3.1.</span> <span class="nav-text">2.1 分布式软件系统(Distributed Software Systems)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-分布式软件系统举例：solrcloud"><span class="nav-number">3.2.</span> <span class="nav-text">2.2 分布式软件系统举例：solrcloud</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-分布式应用系统模拟开发"><span class="nav-number">3.3.</span> <span class="nav-text">2.3 分布式应用系统模拟开发</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-离线数据分析流程介绍"><span class="nav-number">4.</span> <span class="nav-text">3. 离线数据分析流程介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-需求分析"><span class="nav-number">4.1.</span> <span class="nav-text">3.1 需求分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-1-案例名称"><span class="nav-number">4.1.1.</span> <span class="nav-text">3.1.1 案例名称</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-2-案例需求描述"><span class="nav-number">4.1.2.</span> <span class="nav-text">3.1.2 案例需求描述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-3-数据来源"><span class="nav-number">4.1.3.</span> <span class="nav-text">3.1.3 数据来源</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-数据处理流程"><span class="nav-number">4.2.</span> <span class="nav-text">3.2 数据处理流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-1-流程图解析"><span class="nav-number">4.2.1.</span> <span class="nav-text">3.2.1 流程图解析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-2-项目技术架构图"><span class="nav-number">4.2.2.</span> <span class="nav-text">3.2.2 项目技术架构图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-3-项目相关截图（感性认识，欣赏即可）"><span class="nav-number">4.2.3.</span> <span class="nav-text">3.2.3 项目相关截图（感性认识，欣赏即可）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-项目最终效果"><span class="nav-number">4.3.</span> <span class="nav-text">3.3 项目最终效果</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-集群搭建"><span class="nav-number">5.</span> <span class="nav-text">4. 集群搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-HADOOP集群搭建"><span class="nav-number">5.1.</span> <span class="nav-text">4.1 HADOOP集群搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-1集群简介"><span class="nav-number">5.1.1.</span> <span class="nav-text">4.1.1集群简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-2服务器准备"><span class="nav-number">5.1.2.</span> <span class="nav-text">4.1.2服务器准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-3网络环境准备"><span class="nav-number">5.1.3.</span> <span class="nav-text">4.1.3网络环境准备</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-4服务器系统设置"><span class="nav-number">5.1.4.</span> <span class="nav-text">4.1.4服务器系统设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-5-Jdk环境安装"><span class="nav-number">5.1.5.</span> <span class="nav-text">4.1.5 Jdk环境安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-6-HADOOP安装部署"><span class="nav-number">5.1.6.</span> <span class="nav-text">4.1.6 HADOOP安装部署</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-7-启动集群"><span class="nav-number">5.1.7.</span> <span class="nav-text">4.1.7 启动集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-8-测试"><span class="nav-number">5.1.8.</span> <span class="nav-text">4.1.8 测试</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1、上传文件到HDFS"><span class="nav-number">5.1.8.1.</span> <span class="nav-text">1、上传文件到HDFS</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2、运行一个mapreduce程序"><span class="nav-number">5.1.8.2.</span> <span class="nav-text">2、运行一个mapreduce程序</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-集群使用初步"><span class="nav-number">6.</span> <span class="nav-text">5 集群使用初步</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-HDFS使用"><span class="nav-number">6.1.</span> <span class="nav-text">5.1 HDFS使用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-MAPREDUCE使用"><span class="nav-number">6.2.</span> <span class="nav-text">5.2 MAPREDUCE使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-1-Demo开发——wordcount"><span class="nav-number">6.2.1.</span> <span class="nav-text">5.2.1 Demo开发——wordcount</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-2-程序打包运行"><span class="nav-number">6.2.2.</span> <span class="nav-text">5.2.2 程序打包运行</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="heart">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AClearZhang</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">本站总字数&#58;</span>
    
    <span title="本站总字数">445.2k</span>
  
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io" rel="nofollow">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next" rel="nofollow">NexT.Pisces</a> v5.1.4</div>


 
-->

<!-- 百度自动推送 -->
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
      flOptions = {};
      
          flOptions.iconStyle = "default";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>

  
  <script type="text/javascript">
  wpac_init = window.wpac_init || [];
  wpac_init.push({widget: 'Rating', id: 20185,
    el: 'wpac-rating',
    color: 'fc6423'
  });
  (function() {
    if ('WIDGETPACK_LOADED' in window) return;
    WIDGETPACK_LOADED = true;
    var mc = document.createElement('script');
    mc.type = 'text/javascript';
    mc.async = true;
    mc.src = '//embed.widgetpack.com/widget.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(mc, s.nextSibling);
  })();
  </script>


  

  

  

</body>
</html>
  <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
  <!-- 看板娘添加 -->
<script src="/live2d-widget/autoload.js"></script>
