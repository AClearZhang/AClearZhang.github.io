<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.ico?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="今日内容梳理1、mapreduce框架的设计思想 2、mapreduce框架中的程序实体角色：maptask reducetask mrappmaster 3、mapreduce程序运行的整体流程 4、mapreduce程序中maptask任务切片规划的机制（掌握整体逻辑流程，看day03_word文档中的“maptask并行度”） 注意看图 5、mapreduce程序提交的整体流程（看图：一坨">
<meta property="og:type" content="article">
<meta property="og:title" content="day08_BigData渐进学习_aclear_fire">
<meta property="og:url" content="http://blog.aclear.top/post/2efa6d1f.html">
<meta property="og:site_name" content="少年初心">
<meta property="og:description" content="今日内容梳理1、mapreduce框架的设计思想 2、mapreduce框架中的程序实体角色：maptask reducetask mrappmaster 3、mapreduce程序运行的整体流程 4、mapreduce程序中maptask任务切片规划的机制（掌握整体逻辑流程，看day03_word文档中的“maptask并行度”） 注意看图 5、mapreduce程序提交的整体流程（看图：一坨">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2019-10-02T03:40:40.969Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="day08_BigData渐进学习_aclear_fire">
<meta name="twitter:description" content="今日内容梳理1、mapreduce框架的设计思想 2、mapreduce框架中的程序实体角色：maptask reducetask mrappmaster 3、mapreduce程序运行的整体流程 4、mapreduce程序中maptask任务切片规划的机制（掌握整体逻辑流程，看day03_word文档中的“maptask并行度”） 注意看图 5、mapreduce程序提交的整体流程（看图：一坨">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://blog.aclear.top/post/2efa6d1f.html">





  <title>day08_BigData渐进学习_aclear_fire | 少年初心</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">少年初心</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">上进心的男生是有魅力的。不论是学习还是之后工作，有上进心的男生都是发光哒。</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://blog.aclear.top/post/2efa6d1f.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AClearZhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar_acan.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="少年初心">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">day08_BigData渐进学习_aclear_fire</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-24T18:55:05+08:00">
                2018-01-24
              </time>
            

            

            
          </span>

          
            <span class="post-updated">
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i> 
              </span>
              更新于
              <time itemprop="dateUpdated" datetime="2019-10-02T11:40:40+08:00" content="2019-10-02">
                2019-10-02
              </time>
            </span>
          

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Big-Data/" itemprop="url" rel="index">
                    <span itemprop="name">Big Data</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-superpowers"></i> 阅读次数
              <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  11.1k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  46
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="今日内容梳理"><a href="#今日内容梳理" class="headerlink" title="今日内容梳理"></a>今日内容梳理</h2><p>1、mapreduce框架的设计思想 2、mapreduce框架中的程序实体角色：maptask reducetask mrappmaster 3、mapreduce程序运行的整体流程 4、mapreduce程序中maptask任务切片规划的机制（掌握整体逻辑流程，看day03_word文档中的“maptask并行度”） 注意看图 5、mapreduce程序提交的整体流程（看图：一坨 “客户端提交mr程序job的流程”） 注意看图 6、编码： wordcount 流量汇总统计（hadoop的序列化实现） 流量汇总统计并按省份区分   <strong>作业：</strong>1/统计每一个用户（手机号）所耗费的总上行流量、下行流量，总流量 map 读一行，切分字段 抽取手机号，上行流量 下行流量 context.write(手机号,bean) reduce 2/得出上题结果的基础之上再加一个需求：将统计结果按照总流量倒序排序 3/将统计结果按照手机归属地不同省份输出到不同文件中 map 读一行，切分字段 抽取手机号，上行流量 下行流量 context.write(手机号,bean) map输出的数据要分成6个区 重写partitioner，让相同归属地的号码返回相同的分区号int 6省 跑6个reduce task reduce 拿到一个号码所有数据 遍历，累加 输出</p>
<p>What’s more,<br>       <a href="http://blog.aclear.top/2018/02/05/day08-02_bigdatas_learn_aclear_fire/">MapReduce，代码练习、理解增强。</a></p>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p><a href="#_Toc439079660">课程大纲（MAPREDUCE详解）…………………………………………………………………………….. 3</a></p>
<ol>
<li><a href="#_Toc439079661">MAPREDUCE入门………………………………………………………………………………………… 4</a></li>
</ol>
<p><a href="#_Toc439079662">1.1 为什么要MAPREDUCE…………………………………………………………………………….. 4</a> <a href="#_Toc439079663">1.2 MAPREDUCE程序运行演示……………………………………………………………………….. 4</a> <a href="#_Toc439079664">1.3 MAPREDUCE 示例编写及编程规范……………………………………………………………… 4</a> <a href="#_Toc439079665">1.3.1 编程规范……………………………………………………………………………………… 4</a> <a href="#_Toc439079666">1.3.2 wordcount示例编写………………………………………………………………………… 5</a> <a href="#_Toc439079667">1.4 MAPREDUCE程序运行模式及debug方法…………………………………………………….. 7</a> <a href="#_Toc439079668">1.4.1 本地运行模式……………………………………………………………………………….. 7</a> <a href="#_Toc439079669">1.4.2 集群运行模式……………………………………………………………………………….. 7</a></p>
<ol>
<li><a href="#_Toc439079670">Mapreduce程序的核心运行机制………………………………………………………………………… 8</a></li>
</ol>
<p><a href="#_Toc439079671">2.1 概述…………………………………………………………………………………………………….. 8</a> <a href="#_Toc439079672">2.2 mr程序运行流程…………………………………………………………………………………….. 8</a> <a href="#_Toc439079673">2.2.1 流程示意图…………………………………………………………………………………… 8</a> <a href="#_Toc439079674">2.2.2 流程解析……………………………………………………………………………………… 8</a> <a href="#_Toc439079675">2.3 Maptask实例数的决定机制……………………………………………………………………… 10</a> <a href="#_Toc439079676">2.3.1 maptask数量的决定机制………………………………………………………………… 10</a> <a href="#_Toc439079677">2.3.2切片机制：………………………………………………………………………………….. 10</a> <a href="#_Toc439079678">2.4 ReduceTask实例数的决定………………………………………………………………………… 11</a></p>
<ol>
<li><a href="#_Toc439079679">MAPREDUCE中的Combiner……………………………………………………………………………… 12</a></li>
<li><a href="#_Toc439079680">MAPREDUCE中的序列化…………………………………………………………………………………. 12</a></li>
</ol>
<p><a href="#_Toc439079681">4.1 概述…………………………………………………………………………………………………… 12</a> <a href="#_Toc439079682">4.2 Jdk序列化和MR序列化之间的比较………………………………………………………….. 12</a> <a href="#_Toc439079683">4.3 自定义对象实现MR中的序列化接口……………………………………………………….. 13</a></p>
<ol>
<li><a href="#_Toc439079684">Mapreduce中的排序初步………………………………………………………………………………… 16</a></li>
</ol>
<p><a href="#_Toc439079685">5.1 需求：……………………………………………………………………………………………….. 16</a> <a href="#_Toc439079686">5.2 分析…………………………………………………………………………………………………… 16</a> <a href="#_Toc439079687">5.3 实现…………………………………………………………………………………………………… 16</a></p>
<ol>
<li><a href="#_Toc439079688">Mapreduce中的分区Partitioner……………………………………………………………………….. 20</a></li>
</ol>
<p><a href="#_Toc439079689">6.1 需求：……………………………………………………………………………………………….. 20</a> <a href="#_Toc439079690">6.2 分析…………………………………………………………………………………………………… 20</a> <a href="#_Toc439079691">6.3 实现…………………………………………………………………………………………………… 20</a></p>
<ol>
<li><a href="#_Toc439079692">mapreduce的shuffle机制……………………………………………………………………………….. 22</a></li>
</ol>
<p><a href="#_Toc439079693">7.1 概述：……………………………………………………………………………………………….. 22</a> <a href="#_Toc439079694">7.2 主要流程：…………………………………………………………………………………………. 22</a> <a href="#_Toc439079695">7.3 详细流程…………………………………………………………………………………………….. 22</a> <a href="#_Toc439079696">7.4 详细流程示意图…………………………………………………………………………………… 23</a></p>
<ol>
<li><a href="#_Toc439079697">mapreduce数据压缩………………………………………………………………………………………. 24</a></li>
</ol>
<p><a href="#_Toc439079698">8.1 概述…………………………………………………………………………………………………… 24</a> <a href="#_Toc439079699">8.2 MR支持的压缩编码……………………………………………………………………………….. 24</a> <a href="#_Toc439079700">8.3 Reducer输出压缩………………………………………………………………………………….. 24</a> <a href="#_Toc439079701">8.4 Mapper输出压缩…………………………………………………………………………………… 25</a> <a href="#_Toc439079702">8.5 压缩文件的读取…………………………………………………………………………………… 25</a></p>
<ol>
<li><a href="#_Toc439079703">MapReduce与YARN……………………………………………………………………………………….. 27</a></li>
</ol>
<p><a href="#_Toc439079704">9.1 YARN概述……………………………………………………………………………………………. 27</a> <a href="#_Toc439079705">9.2 YARN的重要概念…………………………………………………………………………………… 27</a> <a href="#_Toc439079706">9.3 Yarn中运行运算程序的示例…………………………………………………………………….. 27</a></p>
<ol>
<li><a href="#_Toc439079707">MapReduce编程案例……………………………………………………………………………………. 28</a></li>
</ol>
<p><a href="#_Toc439079708">10.1 reduce端join算法实现…………………………………………………………………… 28</a> <a href="#_Toc439079709">10.2 map端join算法实现……………………………………………………………………… 29</a> <a href="#_Toc439079710">10.3  web日志预处理………………………………………………………………………….. 32</a> <a href="#_Toc439079711">附：Mapreduce参数优化…………………………………………………………………………………… 36</a> <a href="#_Toc439079712">11.1 资源相关参数…………………………………………………………………………………….. 36</a> <a href="#_Toc439079713">11.2 容错相关参数…………………………………………………………………………………….. 37</a> <a href="#_Toc439079714">11.3 本地运行mapreduce 作业……………………………………………………………………. 37</a> <a href="#_Toc439079715">11.4 效率和稳定性相关参数………………………………………………………………………… 37</a>      </p>
<h1 id="课程大纲（MAPREDUCE详解）"><a href="#课程大纲（MAPREDUCE详解）" class="headerlink" title="课程大纲（MAPREDUCE详解）"></a>课程大纲（MAPREDUCE详解）</h1><p>MapReduce快速入门</p>
<p>如何理解map、reduce计算模型</p>
<p>Mapreudce程序运行演示</p>
<p>Mapreduce编程规范及示例编写</p>
<p>Mapreduce程序运行模式及debug方法</p>
<p>MapReduce高级特性</p>
<p>Mapreduce程序的核心机制</p>
<p>MapReduce的序列化框架</p>
<p>MapReduce的排序实现</p>
<p>MapReduce的分区机制及自定义</p>
<p>Mapreduce的数据压缩</p>
<p>Mapreduce与yarn的结合</p>
<p>Mapreduce编程案例</p>
<p>Mapreduce 参数优化</p>
<pre><code>目标： 掌握mapreduce分布式运算框架的编程思想 掌握mapreduce常用算法的编程套路 掌握mapreduce分布式运算框架的运行机制，具备一定自定义开发的能力     回顾：
</code></pre><ol>
<li>hdfs的读取数据</li>
<li>hdfs的写入数据</li>
<li>HDFS注意 进行API操作的时候我们，并不能用客户端进行HDFS文件内容某一行的修改。只能进行 增删查进行HDFS操作。</li>
<li>Mr程序对hdfs的api的页数要求。Datanode进行并发实例，执行对应的指定的一部分进行读取——起始偏移量 到 终止偏移量之间的数值。（mr只是用hdfs执行对应的api，在对应的模块上进行操作。——所以我们说 mr将相当于 hdfs的客户端，mr不需要进行datanode深层的理解。）——以上四个回顾都是有 图片进行形象的回顾的！</li>
<li>浏览器的&lt;浏览器当中 用户js&gt;行为 记录在我们的业务服务器上，注意对应的汇聚到对应的HDFS上.</li>
<li>2018/2/4 驾照考试完成 进行复习整理第一课：</li>
<li>大数据一般 统计的是用户的行为进行的。</li>
<li>关于日志的采集： 我们注意，日志的采集 MR实则是在HADOOP上的客户端似的。</li>
<li>Js 用户采集ftp传输到 我们服务器的本地磁盘当中；然后通过 java或者shell进行日志的采集和处理；并且利用hdfs api 从服务器的本地 上 传到我们自己的hdfs上进行数据的管理和 并发式的处理。</li>
<li>离线 和 spark一般都是写 sql和mapreduce&lt;但是由于 mapreduce 需要很多步才能达到sql的几步！&gt; &lt;项目可以一起串起来！&gt;</li>
</ol>
<h1 id="1-MAPREDUCE原理篇（1）"><a href="#1-MAPREDUCE原理篇（1）" class="headerlink" title="1. MAPREDUCE原理篇（1）"></a>1. MAPREDUCE原理篇（1）</h1><p>_Mapreduce<strong>是一个分布式运算程序的<strong>编程框架</strong>，</strong>是用户开发“基于hadoop<strong>的数据分析应用”的核心框架；_ _Mapreduce_<strong>_核心功能_</strong>_是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，</strong>并发运行在一个hadoop<strong>集群上</strong>；_</p>
<h2 id="1-1-为什么要MAPREDUCE"><a href="#1-1-为什么要MAPREDUCE" class="headerlink" title="1.1 为什么要MAPREDUCE"></a>1.1 为什么要MAPREDUCE</h2><p>（1）海量数据在单机上处理因为硬件资源限制，无法胜任 （2）而一旦将单机版程序扩展到集群来分布式运行，将极大增加程序的复杂度和开发难度 （3）引入mapreduce框架后，开发人员可以将绝大部分工作集中在业务逻辑的开发上，而将分布式计算中的复杂性交由框架来处理   _设想一个海量数据场景下的wordcount__需求：_</p>
<p>单机版：内存受限，磁盘受限，运算能力受限 分布式： 1、文件分布式存储（HDFS） 2、运算逻辑需要至少分成2个阶段（一个阶段独立并发，一个阶段汇聚） 3、运算程序如何分发 4、程序如何分配运算任务（切片） 5、两阶段的程序如何启动？如何协调？ 6、整个程序运行过程中的监控？容错？重试？</p>
<p>注意：图片下面若干复杂的问题  就行相应的解决的思想过程！ 可见在程序由单机版扩成分布式时，会引入大量的复杂工作。为了提高开发效率，可以将分布式程序中的公共功能封装成框架，让开发人员可以将精力集中于业务逻辑。 而mapreduce就是这样一个分布式程序的通用框架，其应对以上问题的整体结构如下：</p>
<p>1、MRAppMaster(mapreduce application master) 2、MapTask 3、ReduceTask</p>
<h2 id="1-2-MAPREDUCE框架结构及核心运行机制"><a href="#1-2-MAPREDUCE框架结构及核心运行机制" class="headerlink" title="1.2 MAPREDUCE框架结构及核心运行机制"></a>1.2 MAPREDUCE框架结构及核心运行机制</h2><h3 id="1-2-1-结构"><a href="#1-2-1-结构" class="headerlink" title="1.2.1 结构"></a>1.2.1 结构</h3><p>一个完整的mapreduce程序在分布式运行时有三类实例进程： 1、MRAppMaster：负责整个程序的过程调度及状态协调 2、MapTask：负责map阶段的整个数据处理流程 3、ReduceTask：负责reduce阶段的整个数据处理流程  </p>
<h3 id="1-2-2-MR程序运行流程"><a href="#1-2-2-MR程序运行流程" class="headerlink" title="1.2.2 MR程序运行流程"></a>1.2.2 MR程序运行流程</h3><h4 id="1-2-2-1-流程示意图"><a href="#1-2-2-1-流程示意图" class="headerlink" title="1.2.2.1 流程示意图"></a>1.2.2.1 流程示意图</h4><h4 id="1-2-2-2-流程解析"><a href="#1-2-2-2-流程解析" class="headerlink" title="1.2.2.2 流程解析"></a>1.2.2.2 流程解析</h4><ul>
<li>一个mr程序启动的时候，最先启动的是MRAppMaster，MRAppMaster启动后根据本次job的描述信息，计算出需要的maptask实例数量，然后向集群申请机器启动相应数量的maptask进程</li>
</ul>
<ul>
<li>maptask进程启动之后，根据给定的数据切片范围进行数据处理，主体流程为：<ol>
<li>利用客户指定的inputformat来获取RecordReader读取数据，形成输入KV对</li>
<li>将输入KV对传递给客户定义的map()方法，做逻辑运算，并将map()方法输出的KV对收集到缓存</li>
<li>将缓存中的KV对按照K分区排序后不断溢写到磁盘文件</li>
</ol>
</li>
</ul>
<ul>
<li>MRAppMaster监控到所有maptask进程任务完成之后，会根据客户指定的参数启动相应数量的reducetask进程，并告知reducetask进程要处理的数据范围（数据分区）</li>
</ul>
<ul>
<li><p>Reducetask进程启动之后，根据MRAppMaster告知的待处理数据所在位置，从若干台maptask运行所在机器上获取到若干个maptask输出结果文件，并在本地进行重新归并排序，然后按照相同key的KV为一个组，调用客户定义的reduce()方法进行逻辑运算，并收集运算输出的结果KV，然后调用客户指定的outputformat将结果数据输出到外部存储</p>
<p>Eclipse 过程构建：注意进行user library的构建——添加 common hdfs yarn mapreduce      </p>
</li>
</ul>
<h2 id="1-3-MapTask并行度决定机制"><a href="#1-3-MapTask并行度决定机制" class="headerlink" title="1.3 MapTask并行度决定机制"></a>1.3 MapTask并行度决定机制</h2><p>_maptask<strong>的并行度决定map</strong>阶段的任务处理并发度，进而影响到整个job<strong>的处理速度_ _那么，mapTask</strong>并行实例是否越多越好呢？其并行度又是如何决定呢？_  </p>
<h3 id="1-3-1-mapTask并行度的决定机制"><a href="#1-3-1-mapTask并行度的决定机制" class="headerlink" title="1.3.1 mapTask并行度的决定机制"></a>1.3.1 mapTask并行度的决定机制</h3><p>一个job的map阶段并行度由客户端在提交job时决定 而客户端对map阶段并行度的规划的基本逻辑为： _将待处理数据执行逻辑切片（即按照一个特定切片大小，将待处理数据划分成逻辑上的多个split<strong>），然后每一个split</strong>分配一个mapTask__并行实例处理_   这段逻辑及形成的切片规划描述文件&lt;生成过程的逻辑 以及 文件写入生成、之后自动删除！&gt;，由FileInputFormat实现类的getSplits()方法完成，其过程如下图： &lt;加上要知道 下面的 三个参数，以及对应的一些方法！&gt; 上图代码错误，max(min()) 是对的。 注意 这个day08分析的切片对应的源码原理，不明白的时候可以再具体的看一下！   &gt;1.1倍，如果切片的大小不超过1.1倍。就把整个长度作为一个切片 给予一个 map去进行处理就行了！ 对应文件写入 job.split   job.xml Shang shang shang 图中了解，切片的大体过程即可。 然而下面的两张图 是观看源码的东西！   掌握 上方的红字  标红的就行！  </p>
<h3 id="1-3-2-FileInputFormat切片机制"><a href="#1-3-2-FileInputFormat切片机制" class="headerlink" title="1.3.2 FileInputFormat切片机制"></a>1.3.2 FileInputFormat切片机制</h3><h4 id="1、切片定义在InputFormat类中的getSplit-方法"><a href="#1、切片定义在InputFormat类中的getSplit-方法" class="headerlink" title="1、切片定义在InputFormat类中的getSplit()方法"></a>1、切片定义在InputFormat类中的getSplit()方法</h4><h4 id="2、FileInputFormat中默认的切片机制："><a href="#2、FileInputFormat中默认的切片机制：" class="headerlink" title="2、FileInputFormat中默认的切片机制："></a>2、FileInputFormat中默认的切片机制：</h4><ol>
<li>简单地按照文件的内容长度进行切片</li>
<li>切片大小，默认等于block大小</li>
<li>切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</li>
</ol>
<p>比如待处理数据有两个文件：</p>
<p>file1.txt    320M file2.txt    10M</p>
<p>  经过FileInputFormat的切片机制运算后，形成的切片信息如下：</p>
<p>file1.txt.split1—  0~128 file1.txt.split2—  128~256 file1.txt.split3—  256~320 file2.txt.split1—  0~10M</p>
<h4 id="3、FileInputFormat中切片的大小的参数配置"><a href="#3、FileInputFormat中切片的大小的参数配置" class="headerlink" title="3、FileInputFormat中切片的大小的参数配置"></a>3、FileInputFormat中切片的大小的参数配置</h4><p>通过分析源码，在FileInputFormat中，计算切片大小的逻辑：Math.max(minSize, Math.min(maxSize, blockSize));  切片主要由这几个值来运算决定</p>
<p>minsize：默认值：1 配置参数： mapreduce.input.fileinputformat.split.minsize</p>
<p>maxsize：默认值：Long.MAXValue 配置参数：mapreduce.input.fileinputformat.split.maxsize</p>
<p>blocksize</p>
<p>因此，<strong>默认情况下，切片大小**</strong>=blocksize** maxsize（切片最大值）： 参数如果调得比blocksize小，则会让切片变小，而且就等于配置的这个参数的值 minsize （切片最小值）： 参数调的比blockSize大，则可以让切片变得比blocksize还大     选择并发数的影响因素：</p>
<ul>
<li>运算节点的硬件配置</li>
<li>运算任务的类型：CPU密集型还是IO密集型</li>
<li><p>运算任务的数据量</p>
<p>Main()方法&lt;之前咱么配置的job参数&gt;去做  生成一个文件。 .xml  框架里面会给我们写！ Job – yarn -MR App Master  -读文件 知道有几个文件 - 文件偏移量 以及相应的数据有多少 -Map Task 交给他 知道有几个切片！知道相应的医改分成几个切片！ 一个切片对应于 一个MapTask实例！ 客户端提交mr程序job的流程：    </p>
</li>
</ul>
<h2 id="1-4-map并行度的经验之谈"><a href="#1-4-map并行度的经验之谈" class="headerlink" title="1.4 map并行度的经验之谈"></a>1.4 map并行度的经验之谈</h2><p>如果硬件配置为2<em>12core + 64G，恰当的map并行度是大约每个节点20-100个map，<strong>最好每个**</strong>map<em>**</em>的执行时间至少一分钟。*</em></p>
<ul>
<li>如果job的每个map或者 reduce task的运行时间都只有30-40秒钟，那么就减少该job的map或者reduce数，每一个task(map|reduce)的setup和加入到调度器中进行调度，这个中间的过程可能都要花费几秒钟，所以如果每个task都非常快就跑完了，就会在task的开始和结束的时候浪费太多的时间。</li>
</ul>
<p>配置task的JVM 可以改善该问题： _（<strong>mapred.job.reuse.jvm.num.tasks</strong>，<strong>默认是1</strong>，表示一个JVM<strong>上最多可以顺序执行的task_ _数目（属于同一个Job</strong>）是1<strong>。也就是说一个task</strong>启一个JVM__）_  </p>
<ul>
<li>如果input的文件非常的大，比如1TB，可以考虑将hdfs上的每个block size设大，比如设成256MB或者512MB</li>
</ul>
<h2 id="1-5-ReduceTask并行度的决定"><a href="#1-5-ReduceTask并行度的决定" class="headerlink" title="1.5 ReduceTask并行度的决定"></a>1.5 ReduceTask并行度的决定</h2><p>reducetask的并行度同样影响整个job的执行并发度和执行效率，但与maptask的并发数由切片数决定不同，Reducetask数量的决定是可以直接手动设置：   //默认值是1，手动设置为4 job.setNumReduceTasks(4);   如果数据分布不均匀，就有可能在reduce阶段产生数据倾斜 _注意： reducetask<strong>数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有1</strong>个reducetask_   _尽量不要运行太多的reduce task<strong>。对大多数job</strong>来说，最好rduce<strong>的个数最多和集群中的reduce</strong>持平，或者比集群的 reduce slots__小。这个对于小集群而言，尤其重要。_    </p>
<h2 id="1-6-MAPREDUCE程序运行演示"><a href="#1-6-MAPREDUCE程序运行演示" class="headerlink" title="1.6 MAPREDUCE程序运行演示"></a>1.6 MAPREDUCE程序运行演示</h2><p>Hadoop的发布包中内置了一个hadoop-mapreduce-example-2.4.1.jar，这个jar包中有各种MR示例程序，可以通过以下步骤运行： 启动hdfs，yarn 然后在集群中的任意一台服务器上启动执行程序（比如运行wordcount）： hadoop jar hadoop-mapreduce-example-2.4.1.jar wordcount  /wordcount/data /wordcount/out</p>
<h1 id="2-MAPREDUCE实践篇（1）"><a href="#2-MAPREDUCE实践篇（1）" class="headerlink" title="2. MAPREDUCE实践篇（1）"></a>2. MAPREDUCE实践篇（1）</h1><h2 id="2-1-MAPREDUCE-示例编写及编程规范"><a href="#2-1-MAPREDUCE-示例编写及编程规范" class="headerlink" title="2.1 MAPREDUCE 示例编写及编程规范"></a>2.1 MAPREDUCE 示例编写及编程规范</h2><h3 id="2-1-1-编程规范"><a href="#2-1-1-编程规范" class="headerlink" title="2.1.1 编程规范"></a>2.1.1 编程规范</h3><ul>
<li><strong>用户编写的程序分成三个部分</strong>：Mapper，Reducer，Driver(提交运行mr程序的客户端)</li>
<li>Mapper的输入数据是KV对的形式（KV的类型可自定义）</li>
<li>Mapper的输出数据是KV对的形式（KV的类型可自定义）</li>
<li>Mapper中的业务逻辑写在map()方法中</li>
<li>map()方法（maptask进程）对每一个<k,v>调用一次 &lt;处理文本的才有行概念,K是起始偏移量 每拿一行调用一次 KV对！&gt;</k,v></li>
<li>Reducer的输入数据类型对应Mapper的输出数据类型，也是KV</li>
<li>Reducer的业务逻辑写在reduce()方法中</li>
<li>Reducetask进程对每一组相同k的<k,v>组调用一次reduce()</k,v></li>
<li>用户自定义的Mapper和Reducer都要继承各自的父类</li>
<li>整个程序需要一个Drvier来进行提交，提交的是一个描述了各种必要信息的job对象</li>
</ul>
<p>—-在第三个、第六个当中 需要进行传输的细节处理&lt;序列化处理> —-但是我们有时需要进行特殊 对象的传输。所以需要自己封装一些特定的bean对象！ —-mapreduce类似于各种各样的 wordcount！  </p>
<h3 id="1-7-2-wordcount示例编写"><a href="#1-7-2-wordcount示例编写" class="headerlink" title="1.7.2 wordcount示例编写"></a>1.7.2 wordcount示例编写</h3><p>需求：在一堆给定的文本文件中统计输出每一个单词出现的总次数 (1)定义一个mapper类</p>
<p>//首先要定义四个泛型的类型 //keyin:  LongWritable    valuein: Text //keyout: Text            valueout:IntWritable /<strong> <em> </em> 会以 key value 传输进来！ <em> KEYIN :默认情况下，是mr框架所读到的一行文本的起始偏移量，long </em> &lt;注意 因为要进行网络传输-序列化long 最好用hadoop自己拥有的精简化的序列化接口，所以直接不用Long 而是利用LongWritable&gt; <em> VALUEIN：默认情况下，是mr框架所读到的一行文本的内容 String，同上用 Text！对应import hadoop包当中的！ \</em> * * KEYOUT:是用户自定义 逻辑处理完成之后输出数据中的key，此处是单词 String <em> VALUEOUT:用户逻辑处理完成之后的 value 此处map出来的value是数据，Integer </em> <em> </em> </strong>@author<em>* acanprince  &amp; aclearzhang \</em> *业务逻辑类 * */ public class WordCountMapper extends Mapper<longwritable, text,="" intwritable="">{ //map方法的生命周期：  框架每传一行数据就被调用一次 //key :  这一行的起始点在文件中的偏移量 //value: 这一行的内容 @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException { //拿到一行数据转换为string String line = value.toString(); //将这一行切分出各个单词 String[] words = line.split(“ “); //遍历数组，输出&lt;单词，1&gt; for(String word:words){ context.write(new Text(word), new IntWritable(1)); } } }</longwritable,></p>
<p>  (2)定义一个reducer类</p>
<pre><code>     //生命周期：框架每传递进来一个kv 组，reduce方法被调用一次 @Override protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException { //定义一个计数器 int count = 0; //遍历这一组kv的所有v，累加到count中 for(IntWritable value:values){ count += value.get(); } context.write(key, new IntWritable(count)); } }
</code></pre><p>  (3)定义一个主类，用来描述job并提交job</p>
<p>public class WordCountRunner { //把业务逻辑相关的信息（哪个是mapper，哪个是reducer，要处理的数据在哪里，输出的结果放哪里……）描述成一个job对象 //把这个描述好的job提交给集群去运行 public static void main(String[] args) throws Exception { Configuration conf = new Configuration(); Job wcjob = Job.getInstance(conf); //指定我这个job所在的jar包 //               wcjob.setJar(“/home/hadoop/wordcount.jar”); wcjob.setJarByClass(WordCountRunner.class);   wcjob.setMapperClass(WordCountMapper.class); wcjob.setReducerClass(WordCountReducer.class); //设置我们的业务逻辑Mapper类的输出key和value的数据类型 wcjob.setMapOutputKeyClass(Text.class); wcjob.setMapOutputValueClass(IntWritable.class); //设置我们的业务逻辑Reducer类的输出key和value的数据类型 wcjob.setOutputKeyClass(Text.class); wcjob.setOutputValueClass(IntWritable.class);   //指定要处理的数据所在的位置 FileInputFormat.setInputPaths(wcjob, “hdfs://hdp-server01:9000/wordcount/data/big.txt”); //指定处理完成之后的结果所保存的位置 FileOutputFormat.setOutputPath(wcjob, new Path(“hdfs://hdp-server01:9000/wordcount/output/“));   //向yarn集群提交这个job boolean res = wcjob.waitForCompletion(true); System.exit(res?0:1); }</p>
<h2 id="2-2-MAPREDUCE程序运行模式"><a href="#2-2-MAPREDUCE程序运行模式" class="headerlink" title="2.2 MAPREDUCE程序运行模式"></a>2.2 MAPREDUCE程序运行模式</h2><h3 id="2-2-1-本地运行模式"><a href="#2-2-1-本地运行模式" class="headerlink" title="2.2.1 本地运行模式"></a>2.2.1 本地运行模式</h3><ul>
<li>mapreduce程序是被提交给LocalJobRunner在本地以单进程的形式运行</li>
<li>而处理的数据及输出结果可以在本地文件系统，也可以在hdfs上</li>
<li>怎样实现本地运行？写一个程序，不要带集群的配置文件（本质是你的mr程序的conf中是否有framework.name=local以及yarn.resourcemanager.hostname参数）</li>
<li><p>_本地模式非常便于进行业务逻辑的debug<strong>，只要在eclipse</strong>中打断点即可_</p>
<p>_如果在windows<strong>下想运行本地模式来测试程序逻辑，需要在windows</strong>中配置环境变量：_ _％HADOOP_HOME<strong>％  =  d:/hadoop-2.6.1_ _%PATH% =_ _％HADOOP_HOME</strong>％\\bin_ _并且要将d:/hadoop-2.6.1<strong>的lib</strong>和bin<strong>目录替换成windows</strong>平台编译的版本_  </p>
</li>
</ul>
<h3 id="2-2-2-集群运行模式"><a href="#2-2-2-集群运行模式" class="headerlink" title="2.2.2 集群运行模式"></a>2.2.2 集群运行模式</h3><ul>
<li>将mapreduce程序提交给yarn集群resourcemanager，分发到很多的节点上并发执行</li>
<li>处理的数据和输出结果应该位于hdfs文件系统</li>
<li>提交集群的实现步骤：</li>
<li>将程序打成JAR包&lt;暂时没有打成可运行的jar包&gt;，然后在集群的任意一个节点上用hadoop命令启动</li>
</ul>
<p>//注意:  $java -cp wordcount.jar cn.itcast.bigdata.mrsimple.WordCountDriver inputpath outputpath  #会因为没有响应的export路径执行命令而不能运行：三个方法：1.在java -cp 后面带上全部的jar文件路径 2.打包jar的时候就全部打进去 3.下面这种hadoop命令进行执行——会自动导出export出命令！ $ hadoop jar wordcount.jar cn.itcast.bigdata.mrsimple.WordCountDriver inputpath outputpath B、直接在linux的eclipse中运行main方法 <strong>（项目中要带参数：mapreduce.framework.name=yarn**</strong>以及yarn<strong>**的两个基本配置）</strong> C、如果要在windows的eclipse中提交job给集群，则要修改YarnRunner类 <a href="http://aclear1:8088/cluster" target="_blank" rel="noopener">http://aclear1:8088/cluster</a> reduce默认是一个，所以会输出1个最终wordcount统计文件！ 注意 yarn给我们先启动，MRApp – Map – Reduce mapreduce程序在集群中运行时的大体流程： 附：在windows平台上访问hadoop时改变自身身份标识的方法之二：    </p>
<h2 id="3-MAPREDUCE中的Combiner"><a href="#3-MAPREDUCE中的Combiner" class="headerlink" title="3. MAPREDUCE中的Combiner"></a>3. MAPREDUCE中的Combiner</h2><ul>
<li>combiner是MR程序中Mapper和Reducer之外的一种组件</li>
<li>combiner组件的父类就是Reducer</li>
<li>combiner和reducer的区别在于运行的位置：</li>
</ul>
<p>Combiner是在每一个maptask所在的节点运行 Reducer是接收全局所有Mapper的输出结果； (4) combiner的意义就是对每一个maptask的输出进行局部汇总，以减小网络传输量 具体实现步骤：</p>
<ul>
<li>自定义一个combiner继承Reducer，重写reduce方法</li>
<li>在job中设置： setCombinerClass(CustomCombiner.class)</li>
</ul>
<p>(5) combiner能够应用的前提是不能影响最终的业务逻辑 而且，combiner的输出kv应该跟reducer的输入kv类型要对应起来  </p>
<ul>
<li>整体之间一个大的流程：&lt;我们写的只是一个小片段，map reduce用我们的逻辑去做。其它的细节有很多——收集、处理、分区、任务分配.&gt;</li>
</ul>
<p>图前三讲运行.wordcount运行过程的解析   Shuffle 机制-&gt;对应于上图的 map和reduce中间细节的处理：SHUFFLE     //指定我们自定义的数据分区器 job.setPartitionerClass(ProvincePartitioner.<strong>class</strong>); //同时指定 响应分区数量的 reducetask的 数量进行 跑分区！ job.setNumReduceTasks(5); ProvincePatitioner.class   ：</p>
<p><strong>package</strong> cn.itcast.bigdata.mr.province.flow;   <strong>import</strong> java.util.HashMap;   <strong>import</strong> org.apache.hadoop.classification.InterfaceAudience.Public; <strong>import</strong> org.apache.hadoop.io.Text; <strong>import</strong> org.apache.hadoop.mapred.JobConf; <strong>import</strong> org.apache.hadoop.mapreduce.Partitioner;  //新的api 是进行继承！     //import org.apache.hadoop.mapred.Partitioner;//这是老的api  是实现       /** * * K2 V2 对应的是map输出的KV类型 <em> </em> <strong>@author</strong> acanprince * <em>/ <strong>public</strong> <strong>class</strong> ProvincePartitioner <strong>extends</strong> Partitioner<text, flowbean=""> { <strong>public</strong> <strong>static</strong> HashMap<string, integer=""> _provinceDict_ = <strong>new</strong> HashMap<string,integer>(); <strong>static</strong> { _provinceDict_.put(“136”, 0); _provinceDict_.put(“137”, 1); _provinceDict_.put(“138”, 2); _provinceDict_.put(“139”, 3); }     @Override <strong>public</strong> <strong>int</strong> getPartition(Text key, FlowBean value, <strong>int</strong> numPartitions) { // <strong>TODO</strong> Auto-generated method stub String prefix = key.toString().substring(0, 3); Integer provinceId = _provinceDict_.get(prefix);   <strong>return</strong> provinceId == <em>*null</em></string,integer></string,></text,></em>?4:provinceId; }   }  </p>
<pre><code>接下来，如果我们想要传输 自己的对象&lt;而不是writable所以需要我们进行，重写writable&gt; 其实，感觉mapreduce程序就是各种各样的wordcount   打字的手法道义需不要要进行训练呢？ 我现在就是只是在利用除了小指等之外的手指进行代码的编程！ 虽然说这样也是挺快的了， 但是   还是有几个单词 英文状态下 打的并不是特别的好~—— 例如  p  u o rb v  烦的一批~!Fighting! Fighting! 我还是需要进行单词的 寻找！  盲打状态下 ，进行还是 比较好的！ 但是 这样子 就感觉不到小指头的存在了。很烦， 另外 之前打的字都是在中文状态下 进行拼写打字的，如果我们用英文打字，Let’s Go:   Wordcount mapreduce test this my jiahaozhang’s ; .test in the last few years I asked my mom will I be handsome or will I be strong~ Number splite 注意切片的大小，既和文件的大小 又和文件的多少有关！ 思考：启动map task多少？ 图 切片示意图 注意切片 可以任意划分，其实其中的切片任务划分是 我们自由定的。 切片大小 ：一个切片对应一个maptask！ 默认是在 Driver当中（HDFS的客户端中自己设置的！ Job 切片大小！）    
</code></pre><h1 id="3-MAPREDUCE原理篇（2）"><a href="#3-MAPREDUCE原理篇（2）" class="headerlink" title="3. MAPREDUCE原理篇（2）"></a>3. MAPREDUCE原理篇（2）</h1><h2 id="3-1-mapreduce的shuffle机制"><a href="#3-1-mapreduce的shuffle机制" class="headerlink" title="3.1 mapreduce的shuffle机制"></a>3.1 mapreduce的shuffle机制</h2><h2 id="3-1-1-概述："><a href="#3-1-1-概述：" class="headerlink" title="3.1.1 概述："></a>3.1.1 概述：</h2><ul>
<li>mapreduce中，map阶段处理的数据如何传递给reduce阶段，是mapreduce框架中最关键的一个流程，这个流程就叫shuffle；</li>
<li>shuffle: 洗牌、发牌——（核心机制：数据分区，排序，缓存）；</li>
<li>具体来说：就是将maptask输出的处理结果数据，分发给reducetask，并在分发的过程中，_对数据按<strong>key</strong>进行了分区和排序；_</li>
</ul>
<h2 id="3-1-2-主要流程："><a href="#3-1-2-主要流程：" class="headerlink" title="3.1.2 主要流程："></a>3.1.2 主要流程：</h2><p>Shuffle缓存流程： shuffle是MR处理流程中的一个过程，它的每一个处理步骤是分散在各个map task和reduce task节点上完成的，整体来看，分为3个操作：</p>
<ul>
<li>分区partition</li>
<li>Sort根据key排序</li>
<li>Combiner进行局部value的合并</li>
</ul>
<h2 id="3-1-3-详细流程"><a href="#3-1-3-详细流程" class="headerlink" title="3.1.3 详细流程"></a>3.1.3 详细流程</h2><ul>
<li>maptask收集我们的map()方法输出的kv对，放到内存缓冲区中</li>
<li>从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</li>
<li>多个溢出文件会被合并成大的溢出文件</li>
<li>在溢出过程中，及合并的过程中，都要调用partitoner进行分组和针对key进行排序</li>
<li>reducetask根据自己的分区号，去各个maptask机器上取相应的结果分区数据</li>
<li>reducetask会取到同一个分区的来自不同maptask的结果文件，reducetask会将这些文件再进行合并（归并排序）</li>
<li><p>合并成大文件后，shuffle的过程也就结束了，后面进入reducetask的逻辑运算过程（从文件中取出一个一个的键值对group，调用用户自定义的reduce()方法）</p>
<p>Shuffle中的缓冲区大小会影响到mapreduce程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快 缓冲区的大小可以通过参数调整,  参数：io.sort.mb  默认100M      </p>
</li>
</ul>
<h2 id="3-1-4-详细流程示意图"><a href="#3-1-4-详细流程示意图" class="headerlink" title="3.1.4 详细流程示意图"></a>3.1.4 详细流程示意图</h2><h2 id="3-2-MAPREDUCE中的序列化"><a href="#3-2-MAPREDUCE中的序列化" class="headerlink" title="3.2. MAPREDUCE中的序列化"></a>3.2. MAPREDUCE中的序列化</h2><h2 id="3-2-1-概述"><a href="#3-2-1-概述" class="headerlink" title="3.2.1 概述"></a>3.2.1 概述</h2><p>Java的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，header，继承体系。。。。），不便于在网络中高效传输； 所以，hadoop自己开发了一套序列化机制（Writable），精简，高效  </p>
<h2 id="3-2-2-Jdk序列化和MR序列化之间的比较"><a href="#3-2-2-Jdk序列化和MR序列化之间的比较" class="headerlink" title="3.2.2 Jdk序列化和MR序列化之间的比较"></a>3.2.2 Jdk序列化和MR序列化之间的比较</h2><p>简单代码验证两种序列化机制的差别：</p>
<p>_public class TestSeri {_ _         public static void main(String[] args) throws Exception {_ _                   //<strong>定义两个</strong>ByteArrayOutputStream<strong>，用来接收不同序列化机制的序列化结果_ _                   ByteArrayOutputStream ba = new ByteArrayOutputStream();_ _                   ByteArrayOutputStream ba2 = new ByteArrayOutputStream();_  _                   //</strong>定义两个<strong>DataOutputStream</strong>，用于将普通对象进行<strong>jdk</strong>标准序列化_ _                   DataOutputStream dout = new DataOutputStream(ba);_ _                   DataOutputStream dout2 = new DataOutputStream(ba2);_ _                   ObjectOutputStream obout = new ObjectOutputStream(dout2);_ _                   //<strong>定义两个</strong>bean<strong>，作为序列化的源对象_ _                   ItemBeanSer itemBeanSer = new ItemBeanSer(1000L, 89.9f);_ _                   ItemBean itemBean = new ItemBean(1000L, 89.9f);_  _                   //</strong>用于比较<strong>String</strong>类型和<strong>Text</strong>类型的序列化差别_ _                  Text atext = new Text(“a”);_ _                   // atext.write(dout);_ _                   itemBean.write(dout);_  _                   byte[] byteArray = ba.toByteArray();_  _                   //__比较序列化结果_ _                   System.out.println(byteArray.length);_ _                   for (byte b : byteArray) {_  _                            System.out.print(b);_ _                            System.out.print(“:”);_ _                   }_  _                  System.out.println(“———————————-“);_  _                   String astr = “a”;_ _                   // dout2.writeUTF(astr);_ _                   obout.writeObject(itemBeanSer);_  _                   byte[] byteArray2 = ba2.toByteArray();_ _                   System.out.println(byteArray2.length);_ _                   for (byte b : byteArray2) {_ _                            System.out.print(b);_ _                            System.out.print(“:”);_ _                   }_ _         }_ _}_</p>
<pre><code>---MORE---  - 测试数据记录 -
</code></pre><p>1363157985066     13726230503  00-FD-07-A4-72-B8:CMCC        120.196.100.82         i02.c.aliimg.com                24     27     2481         24681       200 1363157995052     13826544101  5C-0E-8B-C7-F1-E0:CMCC         120.197.40.4                      4       0         264  0       200 1363157991076     13926435656  20-10-7A-28-CC-0A:CMCC        120.196.100.99                          2         4       132  1512         200 1363154400022     13926251106  5C-0E-8B-8B-B1-50:CMCC        120.197.40.4                      4       0         240  0       200 1363157993044     18211575961  94-71-AC-CD-E6-18:CMCC-EASY       120.196.100.99         iface.qiyi.com  视频网站         15     12     1527         2106         200 1363157995074     84138413         5C-0E-8B-8C-E8-20:7DaysInn   120.197.40.4   122.72.52.12            20     16     4116         1432         200 1363157993055     13560439658  C4-17-FE-BA-DE-D9:CMCC        120.196.100.99                          18         15     1116         954  200 1363157995033     15920133257  5C-0E-8B-C7-BA-20:CMCC        120.197.40.4   sug.so.360.cn  信息安全     20     20     3156         2936         200 1363157983019     13719199419  68-A1-B7-03-07-B1:CMCC-EASY       120.196.100.82                          4       0       240  0       200 1363157984041     13660577991  5C-0E-8B-92-5C-20:CMCC-EASY       120.197.40.4   s19.cnzz.com         站点统计         24     9       6960         690  200 1363157973098     15013685858  5C-0E-8B-C7-F7-90:CMCC         120.197.40.4   rank.ie.sogou.com         搜索引擎         28     27     3659         3538         200 1363157986029     15989002119  E8-99-C4-4E-93-E0:CMCC-EASY        120.196.100.99         www.umeng.com    站点统计         3       3       1938         180  200 1363157992093     13560439658  C4-17-FE-BA-DE-D9:CMCC        120.196.100.99                          15         9       918  4938         200 1363157986041     13480253104  5C-0E-8B-C7-FC-80:CMCC-EASY        120.197.40.4                      3         3       180  180  200 1363157984040     13602846565  5C-0E-8B-8B-B6-00:CMCC        120.197.40.4   2052.flash2-http.qq.com     综合门户         15     12     1938         2910         200 1363157995093     13922314466  00-FD-07-A2-EC-BA:CMCC        120.196.100.82        img.qfc.cn                   12     12     3008         3720         200 1363157982040     13502468823  5C-0A-5B-6A-0B-D4:CMCC-EASY      120.196.100.99         y0.ifengimg.com      综合门户         57     102  7335         110349     200 1363157986072     18320173382  84-25-DB-4F-10-1A:CMCC-EASY       120.196.100.99         input.shouji.sogou.com    搜索引擎         21     18     9531         2412         200 1363157990043     13925057413  00-1F-64-E1-E6-9A:CMCC         120.196.100.55        t3.baidu.com         搜索引擎         69     63     11058       48243       200 1363157988072     13760778710  00-FD-07-A4-7B-08:CMCC        120.196.100.82                          2         2       120  120  200 1363157985066     13726238888  00-FD-07-A4-72-B8:CMCC        120.196.100.82         i02.c.aliimg.com                24     27     2481         24681       200 1363157993055     13560436666  C4-17-FE-BA-DE-D9:CMCC        120.196.100.99                          18         15     1116         954  200</p>
<h2 id="3-2-3-自定义对象实现MR中的序列化接口"><a href="#3-2-3-自定义对象实现MR中的序列化接口" class="headerlink" title="3.2.3 自定义对象实现MR中的序列化接口"></a>3.2.3 自定义对象实现MR中的序列化接口</h2><p>如果需要将自定义的bean放在key中传输，则还需要实现comparable接口，因为mapreduce框中的shuffle过程一定会对key进行排序,此时，自定义的bean实现的接口应该是： public  class  FlowBean  implements  WritableComparable<flowbean> 需要自己实现的方法是：</flowbean></p>
<pre><code>     /\*\* \* 反序列化的方法，反序列化时，从流中读取到的各个字段的顺序应该与序列化时写出去的顺序保持一致 */ @Override public void readFields(DataInput in) throws IOException {   upflow = in.readLong(); dflow = in.readLong(); sumflow = in.readLong();     }   /** * 序列化的方法 */ @Override public void write(DataOutput out) throws IOException {   out.writeLong(upflow); out.writeLong(dflow); //可以考虑不序列化总流量，因为总流量是可以通过上行流量和下行流量计算出来的 out.writeLong(sumflow);   }   @Override public int compareTo(FlowBean o) {   //实现按照sumflow的大小倒序排序 return sumflow&gt;o.getSumflow()?-1:1; }
</code></pre><h2 id="3-3-MapReduce与YARN"><a href="#3-3-MapReduce与YARN" class="headerlink" title="3.3. MapReduce与YARN"></a>3.3. MapReduce与YARN</h2><h2 id="3-3-1-YARN概述"><a href="#3-3-1-YARN概述" class="headerlink" title="3.3.1 YARN概述"></a>3.3.1 YARN概述</h2><p>Yarn是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台，而mapreduce等运算程序则相当于运行于操作系统之上的应用程序</p>
<h2 id="3-3-2-YARN的重要概念"><a href="#3-3-2-YARN的重要概念" class="headerlink" title="3.3.2 YARN的重要概念"></a>3.3.2 YARN的重要概念</h2><ul>
<li>yarn并不清楚用户提交的程序的运行机制</li>
<li>yarn只提供运算资源的调度（用户程序向yarn申请资源，yarn就负责分配资源）</li>
<li>yarn中的主管角色叫ResourceManager</li>
<li>yarn中具体提供运算资源的角色叫NodeManager</li>
<li>这样一来，yarn其实就与运行的用户程序完全解耦，就意味着yarn上可以运行各种类型的分布式运算程序（mapreduce只是其中的一种），比如mapreduce、storm程序，spark程序，tez ……</li>
<li>所以，spark、storm等运算框架都可以整合在yarn上运行，只要他们各自的框架中有符合yarn规范的资源请求机制即可</li>
<li>Yarn就成为一个通用的资源调度平台，从此，企业中以前存在的各种运算集群都可以整合在一个物理集群上，提高资源利用率，方便数据共享</li>
</ul>
<h2 id="3-3-3-Yarn中运行运算程序的示例"><a href="#3-3-3-Yarn中运行运算程序的示例" class="headerlink" title="3.3.3 Yarn中运行运算程序的示例"></a>3.3.3 Yarn中运行运算程序的示例</h2><p>mapreduce程序的调度过程，如下图      </p>
<h1 id="4-MAPREDUCE实践篇（2）"><a href="#4-MAPREDUCE实践篇（2）" class="headerlink" title="4. MAPREDUCE实践篇（2）"></a>4. MAPREDUCE实践篇（2）</h1><h2 id="4-1-Mapreduce中的排序初步"><a href="#4-1-Mapreduce中的排序初步" class="headerlink" title="4.1. Mapreduce中的排序初步"></a>4.1. Mapreduce中的排序初步</h2><h3 id="4-1-1-需求"><a href="#4-1-1-需求" class="headerlink" title="4.1.1 需求"></a>4.1.1 需求</h3><p>对日志数据中的上下行流量信息汇总，并输出按照总流量倒序排序的结果 数据如下：</p>
<p>1363157985066           13726230503   00-FD-07-A4-72-B8:CMCC         120.196.100.82             24          27         2481    24681  200 1363157995052           13826544101   5C-0E-8B-C7-F1-E0:CMCC          120.197.40.4                                4            0            264       0            200 1363157991076           13926435656   20-10-7A-28-CC-0A:CMCC         120.196.100.99                            2            4            132       1512    200 1363154400022           13926251106   5C-0E-8B-8B-B1-50:CMCC         120.197.40.4                                4            0            240       0            200</p>
<h3 id="4-1-2-分析"><a href="#4-1-2-分析" class="headerlink" title="4.1.2 分析"></a>4.1.2 分析</h3><p>基本思路：实现自定义的bean来封装流量信息，并将bean作为map输出的key来传输   MR程序在处理数据的过程中会对数据排序(map输出的kv对传输到reduce之前，会排序)，排序的依据是map输出的key 所以，我们如果要实现自己需要的排序规则，则可以考虑将排序因素放到key中，让key实现接口：WritableComparable 然后重写key的compareTo方法  </p>
<h3 id="4-1-3-实现"><a href="#4-1-3-实现" class="headerlink" title="4.1.3 实现"></a>4.1.3 实现</h3><ul>
<li>自定义的bean</li>
</ul>
<p>public class FlowBean implements WritableComparable<flowbean>{   long upflow; long downflow; long sumflow;   //如果空参构造函数被覆盖，一定要显示定义一下，否则在反序列时会抛异常 public FlowBean(){}   public FlowBean(long upflow, long downflow) { super(); this.upflow = upflow; this.downflow = downflow; this.sumflow = upflow + downflow; }   public long getSumflow() { return sumflow; }   public void setSumflow(long sumflow) { this.sumflow = sumflow; }   public long getUpflow() { return upflow; } public void setUpflow(long upflow) { this.upflow = upflow; } public long getDownflow() { return downflow; } public void setDownflow(long downflow) { this.downflow = downflow; }   //序列化，将对象的字段信息写入输出流 @Override public void write(DataOutput out) throws IOException {   out.writeLong(upflow); out.writeLong(downflow); out.writeLong(sumflow);   }   //反序列化，从输入流中读取各个字段信息 @Override public void readFields(DataInput in) throws IOException { upflow = in.readLong(); downflow = in.readLong(); sumflow = in.readLong();   }     @Override public String toString() { return upflow + “\\t” + downflow + “\\t” + sumflow; } @Override public int compareTo(FlowBean o) { //自定义倒序比较规则 return sumflow &gt; o.getSumflow() ? -1:1; } }</flowbean></p>
<ul>
<li>mapper 和 reducer</li>
</ul>
<p>public class FlowCount {   static class FlowCountMapper extends Mapper<longwritable, text,="" flowbean,text=""> {   @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {   String line = value.toString(); String[] fields = line.split(“\\t”); try { String phonenbr = fields[0];   long upflow = Long.parseLong(fields[1]); long dflow = Long.parseLong(fields[2]);   FlowBean flowBean = new FlowBean(upflow, dflow);   context.write(flowBean,new Text(phonenbr)); } catch (Exception e) {   e.printStackTrace(); }   }   }   static class FlowCountReducer extends Reducer<flowbean,text,text, flowbean=""> {   @Override protected void reduce(FlowBean bean, Iterable<text> phonenbr, Context context) throws IOException, InterruptedException {   Text phoneNbr = phonenbr.iterator().next();   //注意context write出去的，FlowBean对象一定是，字符串。平时注意在输出到时候进行一行行的转化。 //注意此时 输出：toString()方法！ //又反序列化时： 反射运用空参数 构造！！！所以 FlowBean当中要 显示定义一个 显示构造的 FlowBean() 构造参数   context.write(phoneNbr, bean);   }   }   public static void main(String[] args) throws Exception {   Configuration conf = new Configuration();   Job job = Job.getInstance(conf);   job.setJarByClass(FlowCount.class);   job.setMapperClass(FlowCountMapper.class); job.setReducerClass(FlowCountReducer.class);   job.setMapOutputKeyClass(FlowBean.class); job.setMapOutputValueClass(Text.class);   job.setOutputKeyClass(Text.class); job.setOutputValueClass(FlowBean.class);   // job.setInputFormatClass(TextInputFormat.class);   FileInputFormat.setInputPaths(job, new Path(args[0])); FileOutputFormat.setOutputPath(job, new Path(args[1]));   job.waitForCompletion(true);   }   }</text></flowbean,text,text,></longwritable,></p>
<p>运行程序： hadoop jar flowcount.jar cn.itcast.bigdata.mr.flowsum.FlowCount /worcount/input/flowcount.dat /wordcount/output_flowcount //以上是打包成 jar文件  而不是可运行的jar包</p>
<h2 id="4-2-Mapreduce中的分区Partitioner"><a href="#4-2-Mapreduce中的分区Partitioner" class="headerlink" title="4.2. Mapreduce中的分区Partitioner"></a>4.2. Mapreduce中的分区Partitioner</h2><h3 id="4-2-1-需求"><a href="#4-2-1-需求" class="headerlink" title="4.2.1 需求"></a>4.2.1 需求</h3><p>根据归属地输出流量统计数据结果到不同文件，以便于在查询统计结果时可以定位到省级范围进行</p>
<h3 id="4-2-2-分析"><a href="#4-2-2-分析" class="headerlink" title="4.2.2 分析"></a>4.2.2 分析</h3><p>Mapreduce中会将map输出的kv对，按照相同key分组，然后分发给不同的reducetask 默认的分发规则为：根据key的hashcode%reducetask数来分发 所以：如果要按照我们自己的需求进行分组，则需要改写数据分发（分组）组件Partitioner 自定义一个CustomPartitioner继承抽象类：Partitioner 然后在job对象中，设置自定义partitioner： job.setPartitionerClass(CustomPartitioner.class)  </p>
<h3 id="4-2-3-实现"><a href="#4-2-3-实现" class="headerlink" title="4.2.3 实现"></a>4.2.3 实现</h3><p>/** * 定义自己的从map到reduce之间的数据（分组）分发规则 按照手机号所属的省份来分发（分组）ProvincePartitioner <em> 默认的分组组件是HashPartitioner </em> <em> @author </em> */ public class ProvincePartitioner extends Partitioner<text, flowbean=""> {   static HashMap<string, integer=""> provinceMap = new HashMap<string, integer="">();   static {   provinceMap.put(“135”, 0); provinceMap.put(“136”, 1); provinceMap.put(“137”, 2); provinceMap.put(“138”, 3); provinceMap.put(“139”, 4);   }   @Override public int getPartition(Text key, FlowBean value, int numPartitions) {   Integer code = provinceMap.get(key.toString().substring(0, 3));   return code == null ? 5 : code; }   }</string,></string,></text,></p>
<h2 id="4-3-mapreduce数据压缩"><a href="#4-3-mapreduce数据压缩" class="headerlink" title="4.3. mapreduce数据压缩"></a>4.3. mapreduce数据压缩</h2><h3 id="4-3-1-概述"><a href="#4-3-1-概述" class="headerlink" title="4.3.1 概述"></a>4.3.1 概述</h3><p>这是<strong>mapreduce**</strong>的一种优化策略：通过压缩编码对<strong><strong>mapper</strong></strong>或者<strong><strong>reducer</strong></strong>的输出进行压缩，以减少磁盘<strong><strong>IO</strong></strong>，**提高MR程序运行速度（但相应增加了cpu运算负担）</p>
<ul>
<li>Mapreduce支持将map输出的结果或者reduce输出的结果进行压缩，以减少网络IO或最终输出数据的体积</li>
<li>压缩特性运用得当能提高性能，但运用不当也可能降低性能</li>
<li>基本原则：</li>
</ul>
<p>运算密集型的job，少用压缩 IO密集型的job，多用压缩      </p>
<h3 id="4-3-2-MR支持的压缩编码"><a href="#4-3-2-MR支持的压缩编码" class="headerlink" title="4.3.2 MR支持的压缩编码"></a>4.3.2 MR支持的压缩编码</h3><h3 id="4-3-3-Reducer输出压缩"><a href="#4-3-3-Reducer输出压缩" class="headerlink" title="4.3.3 Reducer输出压缩"></a>4.3.3 Reducer输出压缩</h3><p>在配置参数或在代码中都可以设置reduce的输出压缩 1、在配置参数中设置 mapreduce.output.fileoutputformat.compress=false mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec mapreduce.output.fileoutputformat.compress.type=RECORD   2、在代码中设置</p>
<pre><code>               Job job = Job.getInstance(conf); FileOutputFormat.setCompressOutput(job, true); FileOutputFormat.setOutputCompressorClass(job, (Class&lt;? extends CompressionCodec&gt;) Class.forName(&quot;&quot;));
</code></pre><h3 id="4-3-4-Mapper输出压缩"><a href="#4-3-4-Mapper输出压缩" class="headerlink" title="4.3.4 Mapper输出压缩"></a>4.3.4 Mapper输出压缩</h3><p>在配置参数或在代码中都可以设置reduce的输出压缩 1、在配置参数中设置 mapreduce.map.output.compress=false mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.DefaultCodec   2、在代码中设置：</p>
<p>conf.setBoolean(Job.MAP_OUTPUT_COMPRESS, true); conf.setClass(Job.MAP_OUTPUT_COMPRESS_CODEC, GzipCodec.class, CompressionCodec.class);</p>
<h3 id="4-3-5-压缩文件的读取"><a href="#4-3-5-压缩文件的读取" class="headerlink" title="4.3.5 压缩文件的读取"></a>4.3.5 压缩文件的读取</h3><p>Hadoop自带的InputFormat类内置支持压缩文件的读取，比如TextInputformat类，在其initialize方法中：</p>
<p>  public void initialize(InputSplit genericSplit, TaskAttemptContext context) throws IOException { FileSplit split = (FileSplit) genericSplit; Configuration job = context.getConfiguration(); this.maxLineLength = job.getInt(MAX_LINE_LENGTH, Integer.MAX_VALUE); start = split.getStart(); end = start + split.getLength(); final Path file = split.getPath();   // open the file and seek to the start of the split final FileSystem fs = file.getFileSystem(job); fileIn = fs.open(file); //根据文件后缀名创建相应压缩编码的codec CompressionCodec codec = new CompressionCodecFactory(job).getCodec(file); if (null!=codec) { isCompressedInput = true; decompressor = CodecPool.getDecompressor(codec); //判断是否属于可切片压缩编码类型 if (codec instanceof SplittableCompressionCodec) { final SplitCompressionInputStream cIn = ((SplittableCompressionCodec)codec).createInputStream( fileIn, decompressor, start, end, SplittableCompressionCodec.READ_MODE.BYBLOCK); //如果是可切片压缩编码，则创建一个CompressedSplitLineReader读取压缩数据 in = new CompressedSplitLineReader(cIn, job, this.recordDelimiterBytes); start = cIn.getAdjustedStart(); end = cIn.getAdjustedEnd(); filePosition = cIn; } else { //如果是不可切片压缩编码，则创建一个SplitLineReader读取压缩数据，并将文件输入流转换成解压数据流传递给普通SplitLineReader读取 in = new SplitLineReader(codec.createInputStream(fileIn, decompressor), job, this.recordDelimiterBytes); filePosition = fileIn; } } else { fileIn.seek(start); //如果不是压缩文件，则创建普通SplitLineReader读取数据 in = new SplitLineReader(fileIn, job, this.recordDelimiterBytes); filePosition = fileIn; }</p>
<h2 id="4-4-更多MapReduce编程案例"><a href="#4-4-更多MapReduce编程案例" class="headerlink" title="4.4. 更多MapReduce编程案例"></a>4.4. 更多MapReduce编程案例</h2><h3 id="4-4-1-reduce端join算法实现"><a href="#4-4-1-reduce端join算法实现" class="headerlink" title="4.4.1 reduce端join算法实现"></a>4.4.1 reduce端join算法实现</h3><p>1、需求： 订单数据表t_order：</p>
<p>id</p>
<p>date</p>
<p>pid</p>
<p>amount</p>
<p>1001</p>
<p>20150710</p>
<p>P0001</p>
<p>2</p>
<p>1002</p>
<p>20150710</p>
<p>P0001</p>
<p>3</p>
<p>1002</p>
<p>20150710</p>
<p>P0002</p>
<p>3</p>
<p>  商品信息表t_product</p>
<p>id</p>
<p>name</p>
<p>category_id</p>
<p>price</p>
<p>P0001</p>
<p>小米5</p>
<p>C01</p>
<p>2</p>
<p>P0002</p>
<p>锤子T1</p>
<p>C01</p>
<p>3</p>
<p>  假如数据量巨大，两表的数据是以文件的形式存储在HDFS中，需要用mapreduce程序来实现一下SQL查询运算：</p>
<p>select  a.id,a.date,b.name,b.category_id,b.price from t_order a join t_product b on a.pid = b.id</p>
<p>  2、实现机制： 通过将关联的条件作为map输出的key，将两表满足join条件的数据并携带数据所来源的文件信息，发往同一个reduce task，在reduce中进行数据的串联    </p>
<p>public class OrderJoin {   static class OrderJoinMapper extends Mapper<longwritable, text,="" orderjoinbean=""> {   @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {   // 拿到一行数据，并且要分辨出这行数据所属的文件 String line = value.toString();   String[] fields = line.split(“\\t”);   // 拿到itemid String itemid = fields[0];   // 获取到这一行所在的文件名（通过inpusplit） String name = “你拿到的文件名”;   // 根据文件名，切分出各字段（如果是a，切分出两个字段，如果是b，切分出3个字段）   OrderJoinBean bean = new OrderJoinBean(); bean.set(null, null, null, null, null); context.write(new Text(itemid), bean);   }   }   static class OrderJoinReducer extends Reducer<text, orderjoinbean,="" nullwritable=""> {   @Override protected void reduce(Text key, Iterable<orderjoinbean> beans, Context context) throws IOException, InterruptedException {   //拿到的key是某一个itemid,比如1000 //拿到的beans是来自于两类文件的bean //  {1000,amount} {1000,amount} {1000,amount}   —-   {1000,price,name}   //将来自于b文件的bean里面的字段，跟来自于a的所有bean进行字段拼接并输出 } } }</orderjoinbean></text,></longwritable,></p>
<pre><code>缺点：这种方式中，join的操作是在reduce阶段完成，reduce端的处理压力太大，map节点的运算负载则很低，资源利用率不高，且在reduce阶段极易产生数据倾斜   解决方案： map端join实现方式            
</code></pre><h3 id="4-4-2-map端join算法实现"><a href="#4-4-2-map端join算法实现" class="headerlink" title="4.4.2 map端join算法实现"></a>4.4.2 map端join算法实现</h3><p>1、原理阐述 适用于关联表中有小表的情形； 可以将小表分发到所有的map节点，这样，map节点就可以在本地对自己所读到的大表数据进行join并输出最终结果，可以大大提高join操作的并发度，加快处理速度 2、实现示例 —先在mapper类中预先定义好小表，进行join —引入实际场景中的解决方案：一次加载数据库或者用distributedcache</p>
<p>public class TestDistributedCache { static class TestDistributedCacheMapper extends Mapper<longwritable, text,="" text="">{ FileReader in = null; BufferedReader reader = null; HashMap<string,string> b_tab = new HashMap<string, string="">(); String localpath =null; String uirpath = null;   //是在map任务初始化的时候调用一次 @Override protected void setup(Context context) throws IOException, InterruptedException { //通过这几句代码可以获取到cache file的本地绝对路径，测试验证用 Path[] files = context.getLocalCacheFiles(); localpath = files[0].toString(); URI[] cacheFiles = context.getCacheFiles();     //缓存文件的用法——直接用本地IO来读取 //这里读的数据是map task所在机器本地工作目录中的一个小文件 in = new FileReader(“b.txt”); reader =new BufferedReader(in); String line =null; while(null!=(line=reader.readLine())){   String[] fields = line.split(“,”); b_tab.put(fields[0],fields[1]);   } IOUtils.closeStream(reader); IOUtils.closeStream(in);   }   @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {   //这里读的是这个map task所负责的那一个切片数据（在hdfs上） String[] fields = value.toString().split(“\\t”);   String a_itemid = fields[0]; String a_amount = fields[1];   String b_name = b_tab.get(a_itemid);   // 输出结果  1001      98.9 banan context.write(new Text(a_itemid), new Text(a_amount + “\\t” + “:” + localpath + “\\t” +b_name ));   }     }     public static void main(String[] args) throws Exception {   Configuration conf = new Configuration(); Job job = Job.getInstance(conf);   job.setJarByClass(TestDistributedCache.class);   job.setMapperClass(TestDistributedCacheMapper.class);   job.setOutputKeyClass(Text.class); job.setOutputValueClass(LongWritable.class);   //这里是我们正常的需要处理的数据所在路径 FileInputFormat.setInputPaths(job, new Path(args[0])); FileOutputFormat.setOutputPath(job, new Path(args[1]));   //不需要reducer job.setNumReduceTasks(0); //分发一个文件到task进程的工作目录 job.addCacheFile(new URI(“hdfs://hadoop-server01:9000/cachefile/b.txt”));   //分发一个归档文件到task进程的工作目录 //               job.addArchiveToClassPath(archive);   //分发jar包到task节点的classpath下 //               job.addFileToClassPath(jarfile);   job.waitForCompletion(true); } }</string,></string,string></longwritable,></p>
<h3 id="4-4-3-web日志预处理"><a href="#4-4-3-web日志预处理" class="headerlink" title="4.4.3 web日志预处理"></a>4.4.3 web日志预处理</h3><p>1、需求： 对web访问日志中的各字段识别切分 去除日志中不合法的记录 根据KPI统计需求，生成各类访问请求过滤数据   2、实现代码：</p>
<ol>
<li>a) 定义一个bean，用来记录日志数据中的各数据字段</li>
</ol>
<p>public class WebLogBean {   private String remote_addr;// 记录客户端的ip地址 private String remote_user;// 记录客户端用户名称,忽略属性”-“ private String time_local;// 记录访问时间与时区 private String request;// 记录请求的url与http协议 private String status;// 记录请求状态；成功是200 private String body_bytes_sent;// 记录发送给客户端文件主体内容大小 private String http_referer;// 用来记录从那个页面链接访问过来的 private String http_user_agent;// 记录客户浏览器的相关信息   private boolean valid = true;// 判断数据是否合法       public String getRemote_addr() { return remote_addr; }   public void setRemote_addr(String remote_addr) { this.remote_addr = remote_addr; }   public String getRemote_user() { return remote_user; }   public void setRemote_user(String remote_user) { this.remote_user = remote_user; }   public String getTime_local() { return time_local; }   public void setTime_local(String time_local) { this.time_local = time_local; }   public String getRequest() { return request; }   public void setRequest(String request) { this.request = request; }   public String getStatus() { return status; }   public void setStatus(String status) { this.status = status; }   public String getBody_bytes_sent() { return body_bytes_sent; }   public void setBody_bytes_sent(String body_bytes_sent) { this.body_bytes_sent = body_bytes_sent; }   public String getHttp_referer() { return http_referer; }   public void setHttp_referer(String http_referer) { this.http_referer = http_referer; }   public String getHttp_user_agent() { return http_user_agent; }   public void setHttp_user_agent(String http_user_agent) { this.http_user_agent = http_user_agent; }   public boolean isValid() { return valid; }   public void setValid(boolean valid) { this.valid = valid; }     @Override public String toString() { StringBuilder sb = new StringBuilder(); sb.append(this.valid); sb.append(“\\001”).append(this.remote_addr); sb.append(“\\001”).append(this.remote_user); sb.append(“\\001”).append(this.time_local); sb.append(“\\001”).append(this.request); sb.append(“\\001”).append(this.status); sb.append(“\\001”).append(this.body_bytes_sent); sb.append(“\\001”).append(this.http_referer); sb.append(“\\001”).append(this.http_user_agent); return sb.toString(); } }</p>
<p>  b)定义一个parser用来解析过滤web访问日志原始记录</p>
<p>public class WebLogParser { public static WebLogBean parser(String line) { WebLogBean webLogBean = new WebLogBean(); String[] arr = line.split(“ “); if (arr.length &gt; 11) { webLogBean.setRemote_addr(arr[0]); webLogBean.setRemote_user(arr[1]); webLogBean.setTime_local(arr[3].substring(1)); webLogBean.setRequest(arr[6]); webLogBean.setStatus(arr[8]); webLogBean.setBody_bytes_sent(arr[9]); webLogBean.setHttp_referer(arr[10]);   if (arr.length &gt; 12) { webLogBean.setHttp_user_agent(arr[11] + “ “ + arr[12]); } else { webLogBean.setHttp_user_agent(arr[11]); } if (Integer.parseInt(webLogBean.getStatus()) &gt;= 400) {// 大于400，HTTP错误 webLogBean.setValid(false); } } else { webLogBean.setValid(false); } return webLogBean; }   public static String parserTime(String time) {   time.replace(“/“, “-“); return time;   } }</p>
<ol>
<li>c) mapreduce程序</li>
</ol>
<p>public class WeblogPreProcess {   static class WeblogPreProcessMapper extends Mapper<longwritable, text,="" nullwritable=""> { Text k = new Text(); NullWritable v = NullWritable.get();   @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {   String line = value.toString(); WebLogBean webLogBean = WebLogParser.parser(line); if (!webLogBean.isValid()) return; k.set(webLogBean.toString()); context.write(k, v);   }   }   public static void main(String[] args) throws Exception {   Configuration conf = new Configuration(); Job job = Job.getInstance(conf);   job.setJarByClass(WeblogPreProcess.class);   job.setMapperClass(WeblogPreProcessMapper.class);   job.setOutputKeyClass(Text.class); job.setOutputValueClass(NullWritable.class);   FileInputFormat.setInputPaths(job, new Path(args[0])); FileOutputFormat.setOutputPath(job, new Path(args[1]));   job.waitForCompletion(true);   } }</longwritable,></p>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>(っ•̀ω•́)っ✎⁾⁾ 坚持技术学习、内容输出与分享，您的支持将鼓励我继续创作！(*/ω＼*)<br>( • ̀ω•́ )✧如有疑问或需要技术讨论，请留言或发邮件到 aclearzhang@qq.com.(*･ω< ) </div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="http://pic.aclear.top/pay-wechat1.png" alt="AClearZhang 微信支付">
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="http://pic.aclear.top/pay-ali1.png" alt="AClearZhang 支付宝">
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：：</strong>
    AClearZhang
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：：</strong>
    <a href="1142.html" title="day08_BigData渐进学习_aclear_fire">1142.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      

      
      
        <div class="post-widgets">
        
          <div class="wp_rating">
            <div id="wpac-rating"></div>
          </div>
        

        

        
          
          <div id="needsharebutton-postbottom">
            <span class="btn">
              <i class="fa fa-share-alt" aria-hidden="true"></i>
            </span>
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/post/a23cf390.html" rel="next" title="hadoop之路中所有的问题小结">
                <i class="fa fa-chevron-left"></i> hadoop之路中所有的问题小结
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/post/7338d3c.html" rel="prev" title="科目三Fighting总结">
                科目三Fighting总结 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80NTc5Ni8yMjMwNw=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar_acan.jpg" alt="AClearZhang">
            
              <p class="site-author-name" itemprop="name">AClearZhang</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">209</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">120</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/AClearZhang" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:aclearzhang@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://spencerwoo.com/" title="SpenWoo" target="_blank" rel="nofollow">SpenWoo</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.dajipai.cc/" title="鸡排酱" target="_blank" rel="nofollow">鸡排酱</a>
                  </li>
                
              </ul>
            </div>
          

          <!-- none-select-br -->

<p></p>

<!-- hitokoto -->

<div class="hitokoto-title">
	<i class="fa fa-paragraph"></i>
	<b>一言</b>
</div>

<div id="hitokoto">:D 获取中...</div>
<i id="hitofrom">:D 获取中...</i>

<script src="https://cdn.jsdelivr.net/npm/bluebird@3/js/browser/bluebird.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/whatwg-fetch@2.0.3/fetch.min.js"></script>
<script>
  fetch('https://v1.hitokoto.cn')
    .then(function (res){
      return res.json();
    })
    .then(function (data) {
      var hitokoto = document.getElementById('hitokoto');
      hitokoto.innerText = '\xa0\xa0\xa0\xa0\xa0\xa0\xa0' + data.hitokoto;
      var hitofrom = document.getElementById('hitofrom');
      hitofrom.innerText = "——" + data.from + '\xa0'; 
    })
    .catch(function (err) {
      console.error(err);
    })
</script>

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#今日内容梳理"><span class="nav-number">1.</span> <span class="nav-text">今日内容梳理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#目录"><span class="nav-number">2.</span> <span class="nav-text">目录</span></a></li></ol><li class="nav-item nav-level-1"><a class="nav-link" href="#课程大纲（MAPREDUCE详解）"><span class="nav-number"></span> <span class="nav-text">课程大纲（MAPREDUCE详解）</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-MAPREDUCE原理篇（1）"><span class="nav-number"></span> <span class="nav-text">1. MAPREDUCE原理篇（1）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-为什么要MAPREDUCE"><span class="nav-number">1.</span> <span class="nav-text">1.1 为什么要MAPREDUCE</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-MAPREDUCE框架结构及核心运行机制"><span class="nav-number">2.</span> <span class="nav-text">1.2 MAPREDUCE框架结构及核心运行机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-1-结构"><span class="nav-number">2.1.</span> <span class="nav-text">1.2.1 结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-2-MR程序运行流程"><span class="nav-number">2.2.</span> <span class="nav-text">1.2.2 MR程序运行流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-2-1-流程示意图"><span class="nav-number">2.2.1.</span> <span class="nav-text">1.2.2.1 流程示意图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-2-2-流程解析"><span class="nav-number">2.2.2.</span> <span class="nav-text">1.2.2.2 流程解析</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-MapTask并行度决定机制"><span class="nav-number">3.</span> <span class="nav-text">1.3 MapTask并行度决定机制</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-1-mapTask并行度的决定机制"><span class="nav-number">3.1.</span> <span class="nav-text">1.3.1 mapTask并行度的决定机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-2-FileInputFormat切片机制"><span class="nav-number">3.2.</span> <span class="nav-text">1.3.2 FileInputFormat切片机制</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1、切片定义在InputFormat类中的getSplit-方法"><span class="nav-number">3.2.1.</span> <span class="nav-text">1、切片定义在InputFormat类中的getSplit()方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2、FileInputFormat中默认的切片机制："><span class="nav-number">3.2.2.</span> <span class="nav-text">2、FileInputFormat中默认的切片机制：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3、FileInputFormat中切片的大小的参数配置"><span class="nav-number">3.2.3.</span> <span class="nav-text">3、FileInputFormat中切片的大小的参数配置</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-map并行度的经验之谈"><span class="nav-number">4.</span> <span class="nav-text">1.4 map并行度的经验之谈</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-5-ReduceTask并行度的决定"><span class="nav-number">5.</span> <span class="nav-text">1.5 ReduceTask并行度的决定</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-6-MAPREDUCE程序运行演示"><span class="nav-number">6.</span> <span class="nav-text">1.6 MAPREDUCE程序运行演示</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-MAPREDUCE实践篇（1）"><span class="nav-number"></span> <span class="nav-text">2. MAPREDUCE实践篇（1）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-MAPREDUCE-示例编写及编程规范"><span class="nav-number">1.</span> <span class="nav-text">2.1 MAPREDUCE 示例编写及编程规范</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-1-编程规范"><span class="nav-number">1.1.</span> <span class="nav-text">2.1.1 编程规范</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-7-2-wordcount示例编写"><span class="nav-number">1.2.</span> <span class="nav-text">1.7.2 wordcount示例编写</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-MAPREDUCE程序运行模式"><span class="nav-number">2.</span> <span class="nav-text">2.2 MAPREDUCE程序运行模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-1-本地运行模式"><span class="nav-number">2.1.</span> <span class="nav-text">2.2.1 本地运行模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-2-集群运行模式"><span class="nav-number">2.2.</span> <span class="nav-text">2.2.2 集群运行模式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-MAPREDUCE中的Combiner"><span class="nav-number">3.</span> <span class="nav-text">3. MAPREDUCE中的Combiner</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-MAPREDUCE原理篇（2）"><span class="nav-number"></span> <span class="nav-text">3. MAPREDUCE原理篇（2）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-mapreduce的shuffle机制"><span class="nav-number">1.</span> <span class="nav-text">3.1 mapreduce的shuffle机制</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-1-概述："><span class="nav-number">2.</span> <span class="nav-text">3.1.1 概述：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-2-主要流程："><span class="nav-number">3.</span> <span class="nav-text">3.1.2 主要流程：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-3-详细流程"><span class="nav-number">4.</span> <span class="nav-text">3.1.3 详细流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-4-详细流程示意图"><span class="nav-number">5.</span> <span class="nav-text">3.1.4 详细流程示意图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-MAPREDUCE中的序列化"><span class="nav-number">6.</span> <span class="nav-text">3.2. MAPREDUCE中的序列化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-1-概述"><span class="nav-number">7.</span> <span class="nav-text">3.2.1 概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-2-Jdk序列化和MR序列化之间的比较"><span class="nav-number">8.</span> <span class="nav-text">3.2.2 Jdk序列化和MR序列化之间的比较</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-3-自定义对象实现MR中的序列化接口"><span class="nav-number">9.</span> <span class="nav-text">3.2.3 自定义对象实现MR中的序列化接口</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-MapReduce与YARN"><span class="nav-number">10.</span> <span class="nav-text">3.3. MapReduce与YARN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-1-YARN概述"><span class="nav-number">11.</span> <span class="nav-text">3.3.1 YARN概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-2-YARN的重要概念"><span class="nav-number">12.</span> <span class="nav-text">3.3.2 YARN的重要概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-3-Yarn中运行运算程序的示例"><span class="nav-number">13.</span> <span class="nav-text">3.3.3 Yarn中运行运算程序的示例</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-MAPREDUCE实践篇（2）"><span class="nav-number"></span> <span class="nav-text">4. MAPREDUCE实践篇（2）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-Mapreduce中的排序初步"><span class="nav-number">1.</span> <span class="nav-text">4.1. Mapreduce中的排序初步</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-1-需求"><span class="nav-number">1.1.</span> <span class="nav-text">4.1.1 需求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-2-分析"><span class="nav-number">1.2.</span> <span class="nav-text">4.1.2 分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-3-实现"><span class="nav-number">1.3.</span> <span class="nav-text">4.1.3 实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-Mapreduce中的分区Partitioner"><span class="nav-number">2.</span> <span class="nav-text">4.2. Mapreduce中的分区Partitioner</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-需求"><span class="nav-number">2.1.</span> <span class="nav-text">4.2.1 需求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-2-分析"><span class="nav-number">2.2.</span> <span class="nav-text">4.2.2 分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-3-实现"><span class="nav-number">2.3.</span> <span class="nav-text">4.2.3 实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-mapreduce数据压缩"><span class="nav-number">3.</span> <span class="nav-text">4.3. mapreduce数据压缩</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-1-概述"><span class="nav-number">3.1.</span> <span class="nav-text">4.3.1 概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-2-MR支持的压缩编码"><span class="nav-number">3.2.</span> <span class="nav-text">4.3.2 MR支持的压缩编码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-3-Reducer输出压缩"><span class="nav-number">3.3.</span> <span class="nav-text">4.3.3 Reducer输出压缩</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-4-Mapper输出压缩"><span class="nav-number">3.4.</span> <span class="nav-text">4.3.4 Mapper输出压缩</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-5-压缩文件的读取"><span class="nav-number">3.5.</span> <span class="nav-text">4.3.5 压缩文件的读取</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-4-更多MapReduce编程案例"><span class="nav-number">4.</span> <span class="nav-text">4.4. 更多MapReduce编程案例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-1-reduce端join算法实现"><span class="nav-number">4.1.</span> <span class="nav-text">4.4.1 reduce端join算法实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-2-map端join算法实现"><span class="nav-number">4.2.</span> <span class="nav-text">4.4.2 map端join算法实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-3-web日志预处理"><span class="nav-number">4.3.</span> <span class="nav-text">4.4.3 web日志预处理</span></a></li></ol></li></ol></li></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="heart">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AClearZhang</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">本站总字数&#58;</span>
    
    <span title="本站总字数">443.3k</span>
  
</div>

<!--

  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io" rel="nofollow">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next" rel="nofollow">NexT.Pisces</a> v5.1.4</div>


 
-->

<!-- 百度自动推送 -->
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
      flOptions = {};
      
          flOptions.iconStyle = "default";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script>

  
  <script type="text/javascript">
  wpac_init = window.wpac_init || [];
  wpac_init.push({widget: 'Rating', id: 20185,
    el: 'wpac-rating',
    color: 'fc6423'
  });
  (function() {
    if ('WIDGETPACK_LOADED' in window) return;
    WIDGETPACK_LOADED = true;
    var mc = document.createElement('script');
    mc.type = 'text/javascript';
    mc.async = true;
    mc.src = '//embed.widgetpack.com/widget.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(mc, s.nextSibling);
  })();
  </script>


  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
  <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
  <!-- 看板娘添加 -->
<script src="/live2d-widget/autoload.js"></script>
